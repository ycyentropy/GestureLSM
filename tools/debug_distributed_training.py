#!/usr/bin/env python3
"""
åˆ†å¸ƒå¼è®­ç»ƒæ¶æ„è°ƒè¯•è„šæœ¬
æµ‹è¯•torch.distributedçš„å„ä¸ªç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
sys.path.append('/home/embodied/yangchenyu/GestureLSM')

import torch
import torch.distributed as dist
import torch.multiprocessing as mp
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader, DistributedSampler
import time
import traceback

def test_distributed_init(rank, world_size):
    """æµ‹è¯•åˆ†å¸ƒå¼åˆå§‹åŒ–"""
    print(f"[è¿›ç¨‹ {rank}] å¼€å§‹æµ‹è¯•åˆ†å¸ƒå¼åˆå§‹åŒ–...")

    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['MASTER_ADDR'] = 'localhost'
        os.environ['MASTER_PORT'] = '12355'
        os.environ['RANK'] = str(rank)
        os.environ['WORLD_SIZE'] = str(world_size)

        # åˆå§‹åŒ–è¿›ç¨‹ç»„
        dist.init_process_group("nccl", rank=rank, world_size=world_size)
        print(f"[è¿›ç¨‹ {rank}] âœ“ è¿›ç¨‹ç»„åˆå§‹åŒ–æˆåŠŸ")

        # æµ‹è¯•è®¾å¤‡è®¾ç½®
        device = torch.device(f"cuda:{rank}")
        torch.cuda.set_device(rank)
        print(f"[è¿›ç¨‹ {rank}] âœ“ è®¾å¤‡è®¾ç½®æˆåŠŸ: {device}")

        # æµ‹è¯•è¿›ç¨‹é—´é€šä¿¡
        if rank == 0:
            tensor = torch.tensor([rank], device=device)
            print(f"[è¿›ç¨‹ {rank}] å‘é€å¼ é‡: {tensor}")
        else:
            tensor = torch.zeros(1, device=device)

        # å¹¿æ’­æµ‹è¯•
        dist.broadcast(tensor, src=0)
        print(f"[è¿›ç¨‹ {rank}] âœ“ å¹¿æ’­æµ‹è¯•æˆåŠŸï¼Œæ¥æ”¶åˆ°: {tensor}")

        # æ¸…ç†
        dist.destroy_process_group()
        print(f"[è¿›ç¨‹ {rank}] âœ“ è¿›ç¨‹ç»„é”€æ¯æˆåŠŸ")

        return True

    except Exception as e:
        print(f"[è¿›ç¨‹ {rank}] âœ— åˆ†å¸ƒå¼åˆå§‹åŒ–å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_distributed_model(rank, world_size):
    """æµ‹è¯•åˆ†å¸ƒå¼æ¨¡å‹åŒ…è£…"""
    print(f"[è¿›ç¨‹ {rank}] å¼€å§‹æµ‹è¯•åˆ†å¸ƒå¼æ¨¡å‹...")

    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['MASTER_ADDR'] = 'localhost'
        os.environ['MASTER_PORT'] = '12356'
        os.environ['RANK'] = str(rank)
        os.environ['WORLD_SIZE'] = str(world_size)

        # åˆå§‹åŒ–è¿›ç¨‹ç»„
        dist.init_process_group("nccl", rank=rank, world_size=world_size)

        # åˆ›å»ºç®€å•æ¨¡å‹
        device = torch.device(f"cuda:{rank}")
        model = torch.nn.Linear(156, 156).to(device)

        # åŒ…è£…ä¸ºDDPæ¨¡å‹
        ddp_model = DDP(model, device_ids=[rank])
        print(f"[è¿›ç¨‹ {rank}] âœ“ DDPæ¨¡å‹åŒ…è£…æˆåŠŸ")

        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 4
        seq_len = 64
        input_tensor = torch.randn(batch_size, seq_len, 156, device=device)

        output = ddp_model(input_tensor)
        print(f"[è¿›ç¨‹ {rank}] âœ“ DDPå‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")

        # æ¸…ç†
        dist.destroy_process_group()
        return True

    except Exception as e:
        print(f"[è¿›ç¨‹ {rank}] âœ— åˆ†å¸ƒå¼æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_distributed_dataloader(rank, world_size):
    """æµ‹è¯•åˆ†å¸ƒå¼æ•°æ®åŠ è½½å™¨"""
    print(f"[è¿›ç¨‹ {rank}] å¼€å§‹æµ‹è¯•åˆ†å¸ƒå¼æ•°æ®åŠ è½½å™¨...")

    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['MASTER_ADDR'] = 'localhost'
        os.environ['MASTER_PORT'] = '12357'
        os.environ['RANK'] = str(rank)
        os.environ['WORLD_SIZE'] = str(world_size)

        # åˆå§‹åŒ–è¿›ç¨‹ç»„
        dist.init_process_group("nccl", rank=rank, world_size=world_size)

        # åˆ›å»ºæ•°æ®é›†ï¼ˆä½¿ç”¨å°‘é‡æ•°æ®å¿«é€Ÿæµ‹è¯•ï¼‰
        from lazy_window_dataset import CachedLazySeamlessInteractionWindowDataset

        dataset = CachedLazySeamlessInteractionWindowDataset(
            data_path="/home/embodied/yangchenyu/GestureLSM/datasets/seamless_interaction",
            split="train",
            window_size=64,
            window_stride=20,
            multi_length_training=[1.0],  # åªç”¨å•é•¿åº¦é¿å…å¤æ‚æ€§
            load_video=False,
            load_audio=False,
            max_samples=10,  # åªç”¨10ä¸ªæ ·æœ¬
            cache_path="datasets/window_params/window_params_train_ws64_ws20_fixed.pkl"
        )

        print(f"[è¿›ç¨‹ {rank}] æ•°æ®é›†é•¿åº¦: {len(dataset)}")

        # åˆ›å»ºåˆ†å¸ƒå¼é‡‡æ ·å™¨
        sampler = DistributedSampler(
            dataset,
            num_replicas=world_size,
            rank=rank,
            shuffle=True,
            drop_last=True
        )
        print(f"[è¿›ç¨‹ {rank}] âœ“ åˆ†å¸ƒå¼é‡‡æ ·å™¨åˆ›å»ºæˆåŠŸ")

        # åˆ›å»ºDataLoader
        def simple_collate_fn(batch):
            max_len = max(item['pose'].shape[0] for item in batch)
            batch_size = len(batch)
            pose_dim = batch[0]['pose'].shape[1]

            poses = torch.zeros(batch_size, max_len, pose_dim)
            for i, item in enumerate(batch):
                pose = item['pose']
                length = pose.shape[0]
                poses[i, :length] = pose

            return {'pose': poses, 'mask': torch.ones(batch_size, max_len, dtype=torch.bool)}

        dataloader = DataLoader(
            dataset,
            batch_size=2,
            sampler=sampler,
            num_workers=0,
            drop_last=True,
            collate_fn=simple_collate_fn,
            pin_memory=True
        )
        print(f"[è¿›ç¨‹ {rank}] âœ“ DataLoaderåˆ›å»ºæˆåŠŸï¼Œæ‰¹æ¬¡æ•°: {len(dataloader)}")

        # æµ‹è¯•è·å–ä¸€ä¸ªæ‰¹æ¬¡
        start_time = time.time()
        for i, batch in enumerate(dataloader):
            batch_time = time.time()
            print(f"[è¿›ç¨‹ {rank}] âœ“ æ‰¹æ¬¡ {i} è·å–æˆåŠŸï¼Œè€—æ—¶: {batch_time - start_time:.2f}ç§’")
            print(f"[è¿›ç¨‹ {rank}]   æ‰¹æ¬¡å½¢çŠ¶: {batch['pose'].shape}")
            break  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªæ‰¹æ¬¡

        # æ¸…ç†
        dist.destroy_process_group()
        return True

    except Exception as e:
        print(f"[è¿›ç¨‹ {rank}] âœ— åˆ†å¸ƒå¼æ•°æ®åŠ è½½å™¨æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_full_distributed_training(rank, world_size):
    """æµ‹è¯•å®Œæ•´çš„åˆ†å¸ƒå¼è®­ç»ƒæµç¨‹"""
    print(f"[è¿›ç¨‹ {rank}] å¼€å§‹æµ‹è¯•å®Œæ•´åˆ†å¸ƒå¼è®­ç»ƒ...")

    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['MASTER_ADDR'] = 'localhost'
        os.environ['MASTER_PORT'] = '12358'
        os.environ['RANK'] = str(rank)
        os.environ['WORLD_SIZE'] = str(world_size)

        # åˆå§‹åŒ–è¿›ç¨‹ç»„
        dist.init_process_group("nccl", rank=rank, world_size=world_size)
        device = torch.device(f"cuda:{rank}")

        print(f"[è¿›ç¨‹ {rank}] âœ“ è¿›ç¨‹ç»„åˆå§‹åŒ–æˆåŠŸ")

        # åˆ›å»ºæ¨¡å‹
        class SimpleModel(torch.nn.Module):
            def __init__(self):
                super().__init__()
                self.linear = torch.nn.Linear(156, 156)

            def forward(self, x):
                return self.linear(x)

        model = SimpleModel().to(device)
        ddp_model = DDP(model, device_ids=[rank])
        print(f"[è¿›ç¨‹ {rank}] âœ“ æ¨¡å‹åˆ›å»ºå’ŒDDPåŒ…è£…æˆåŠŸ")

        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(ddp_model.parameters(), lr=1e-4)
        print(f"[è¿›ç¨‹ {rank}] âœ“ ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")

        # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
        from lazy_window_dataset import CachedLazySeamlessInteractionWindowDataset

        dataset = CachedLazySeamlessInteractionWindowDataset(
            data_path="/home/embodied/yangchenyu/GestureLSM/datasets/seamless_interaction",
            split="train",
            window_size=64,
            window_stride=20,
            multi_length_training=[1.0],
            load_video=False,
            load_audio=False,
            max_samples=10,
            cache_path="datasets/window_params/window_params_train_ws64_ws20_fixed.pkl"
        )

        sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank, shuffle=False)

        def simple_collate_fn(batch):
            max_len = max(item['pose'].shape[0] for item in batch)
            batch_size = len(batch)
            pose_dim = batch[0]['pose'].shape[1]
            poses = torch.zeros(batch_size, max_len, pose_dim)
            for i, item in enumerate(batch):
                pose = item['pose']
                length = pose.shape[0]
                poses[i, :length] = pose
            return {'pose': poses, 'mask': torch.ones(batch_size, max_len, dtype=torch.bool)}

        dataloader = DataLoader(
            dataset,
            batch_size=2,
            sampler=sampler,
            num_workers=0,
            collate_fn=simple_collate_fn
        )
        print(f"[è¿›ç¨‹ {rank}] âœ“ æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")

        # è®­ç»ƒå¾ªç¯æµ‹è¯•ï¼ˆ2ä¸ªè¿­ä»£ï¼‰
        print(f"[è¿›ç¨‹ {rank}] å¼€å§‹è®­ç»ƒå¾ªç¯æµ‹è¯•...")
        for epoch in range(1):
            sampler.set_epoch(epoch)

            for i, batch in enumerate(dataloader):
                if i >= 2:  # åªæµ‹è¯•2ä¸ªæ‰¹æ¬¡
                    break

                start_time = time.time()

                # æ•°æ®ç§»åˆ°GPU
                gt_motion = batch['pose'].to(device)

                # å‰å‘ä¼ æ’­
                pred_motion = ddp_model(gt_motion)

                # è®¡ç®—æŸå¤±
                loss = torch.nn.functional.mse_loss(pred_motion, gt_motion)

                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                end_time = time.time()
                print(f"[è¿›ç¨‹ {rank}] âœ“ è¿­ä»£ {i} å®Œæˆï¼ŒæŸå¤±: {loss.item():.5f}ï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")

        # æ¸…ç†
        dist.destroy_process_group()
        print(f"[è¿›ç¨‹ {rank}] âœ“ å®Œæ•´åˆ†å¸ƒå¼è®­ç»ƒæµ‹è¯•æˆåŠŸ")
        return True

    except Exception as e:
        print(f"[è¿›ç¨‹ {rank}] âœ— å®Œæ•´åˆ†å¸ƒå¼è®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def run_test(test_func, world_size, test_name):
    """è¿è¡Œæµ‹è¯•å‡½æ•°"""
    print(f"\n=== {test_name} ===")
    print(f"ä½¿ç”¨ {world_size} ä¸ªGPUè¿›è¡Œæµ‹è¯•...")

    try:
        # æ£€æŸ¥GPUæ•°é‡
        if torch.cuda.device_count() < world_size:
            print(f"âŒ å¯ç”¨GPUæ•°é‡({torch.cuda.device_count()})å°‘äºæ‰€éœ€æ•°é‡({world_size})")
            return False

        # å¯åŠ¨å¤šè¿›ç¨‹æµ‹è¯•
        mp.spawn(test_func, args=(world_size,), nprocs=world_size, join=True)
        print(f"âœ… {test_name} å®Œæˆ")
        return True

    except Exception as e:
        print(f"âŒ {test_name} å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def main():
    print("=== åˆ†å¸ƒå¼è®­ç»ƒæ¶æ„è°ƒè¯• ===")

    # æ£€æŸ¥CUDA
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨")
        return

    print(f"âœ… CUDAå¯ç”¨ï¼ŒGPUæ•°é‡: {torch.cuda.device_count()}")

    # æµ‹è¯•ä¸åŒæ•°é‡çš„GPU
    test_world_sizes = [2, 4]  # å…ˆæµ‹è¯•å°è§„æ¨¡ï¼Œé¿å…èµ„æºä¸è¶³

    for world_size in test_world_sizes:
        print(f"\n{'='*50}")
        print(f"æµ‹è¯• {world_size} GPU åˆ†å¸ƒå¼è®­ç»ƒ")
        print(f"{'='*50}")

        # 1. æµ‹è¯•åˆ†å¸ƒå¼åˆå§‹åŒ–
        if not run_test(test_distributed_init, world_size, f"{world_size}GPU åˆ†å¸ƒå¼åˆå§‹åŒ–æµ‹è¯•"):
            continue

        # 2. æµ‹è¯•åˆ†å¸ƒå¼æ¨¡å‹
        if not run_test(test_distributed_model, world_size, f"{world_size}GPU åˆ†å¸ƒå¼æ¨¡å‹æµ‹è¯•"):
            continue

        # 3. æµ‹è¯•åˆ†å¸ƒå¼æ•°æ®åŠ è½½å™¨
        if not run_test(test_distributed_dataloader, world_size, f"{world_size}GPU åˆ†å¸ƒå¼æ•°æ®åŠ è½½å™¨æµ‹è¯•"):
            continue

        # 4. æµ‹è¯•å®Œæ•´åˆ†å¸ƒå¼è®­ç»ƒ
        if not run_test(test_full_distributed_training, world_size, f"{world_size}GPU å®Œæ•´åˆ†å¸ƒå¼è®­ç»ƒæµ‹è¯•"):
            continue

    print(f"\n{'='*50}")
    print("ğŸ‰ æ‰€æœ‰åˆ†å¸ƒå¼è®­ç»ƒç»„ä»¶æµ‹è¯•å®Œæˆ")
    print(f"{'='*50}")

if __name__ == "__main__":
    main()