#!/usr/bin/env python3
"""
Seamlessæ•°æ®é›†è¿åŠ¨é‡å»ºæ¨ç†è„šæœ¬

è¯¥è„šæœ¬ç”¨äºseamlessæ•°æ®é›†å•ä¸ªæ–‡ä»¶çš„è¿åŠ¨é‡å»ºï¼Œæ”¯æŒï¼š
1. è¯»å–åŸå§‹è¿åŠ¨æ•°æ®NPZæ–‡ä»¶
2. å¯¹åŸå§‹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
3. åˆ†å‰²æ•°æ®ä¸ºä¸‰ç§äººä½“éƒ¨ä½ï¼ˆupperã€lowerã€handsï¼‰
4. è¯»å–å¯¹åº”çš„ä¸‰ç§é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†
5. æ‹¼æ¥æ‰€æœ‰éƒ¨ä½çš„é¢„æµ‹ç»“æœ
6. ç»è¿‡åå½’ä¸€åŒ–å¾—åˆ°é‡å»ºåçš„è¿åŠ¨æ•°æ®NPZæ–‡ä»¶

"""

import os
import numpy as np
import torch
import argparse
import logging
import sys
from tqdm import tqdm

# é¡¹ç›®å†…éƒ¨å¯¼å…¥
from models.vq.model import RVQVAE
import utils.rotation_conversions as rc


def validate_input_file(npz_path):
    """éªŒè¯è¾“å…¥NPZæ–‡ä»¶çš„å®Œæ•´æ€§"""
    required_keys = [
        "smplh:global_orient",
        "smplh:body_pose",
        "smplh:left_hand_pose",
        "smplh:right_hand_pose",
        "smplh:translation"
    ]

    try:
        data = np.load(npz_path)
        for key in required_keys:
            if key not in data:
                raise ValueError(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {key}")

        # æ£€æŸ¥æ•°æ®ç»´åº¦
        seq_len = data["smplh:global_orient"].shape[0]
        for key in required_keys:
            if data[key].shape[0] != seq_len:
                raise ValueError(f"å­—æ®µ{key}çš„åºåˆ—é•¿åº¦ä¸ä¸€è‡´")

        return True, data
    except Exception as e:
        return False, str(e)


def validate_models_exist(model_paths):
    """éªŒè¯æ‰€æœ‰æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    for body_part, path in model_paths.items():
        if not os.path.exists(path):
            raise FileNotFoundError(f"{body_part}æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {path}")


def setup_logger(output_dir):
    """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
    logger = logging.getLogger('SeamlessReconstruction')
    logger.setLevel(logging.INFO)

    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(os.path.join(output_dir, 'reconstruction.log'))
    file_handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s %(message)s'))

    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s %(message)s'))

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger


def axis_angle_to_6d(poses_axis_angle):
    """å°†è½´è§’è¡¨ç¤ºè½¬æ¢ä¸º6Dæ—‹è½¬è¡¨ç¤º"""
    # poses_axis_angle: (seq_len, 156) è½´è§’è¡¨ç¤º
    # é¦–å…ˆé‡å¡‘ä¸º (seq_len, 52, 3)
    poses_reshaped = poses_axis_angle.reshape(-1, 52, 3)

    # è½¬æ¢ä¸ºtorch tensor
    poses_tensor = torch.from_numpy(poses_reshaped)

    # è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
    poses_matrix = rc.axis_angle_to_matrix(poses_tensor)

    # è½¬æ¢ä¸º6Dè¡¨ç¤º
    poses_6d = rc.matrix_to_rotation_6d(poses_matrix)

    return poses_6d.reshape(-1, 312).numpy()  # (seq_len, 312)


def d6_to_axis_angle(poses_6d):
    """å°†6Dæ—‹è½¬è¡¨ç¤ºè½¬æ¢å›è½´è§’è¡¨ç¤º"""
    # poses_6d: (seq_len, 312) 6Dè¡¨ç¤º
    poses_6d_reshaped = poses_6d.reshape(-1, 52, 6)

    # è½¬æ¢ä¸ºtorch tensor
    poses_6d_tensor = torch.from_numpy(poses_6d_reshaped)

    poses_matrix = rc.rotation_6d_to_matrix(poses_6d_tensor)
    poses_axis_angle = rc.matrix_to_axis_angle(poses_matrix)

    # è½¬æ¢å›numpy
    return poses_axis_angle.numpy().reshape(-1, 156)  # (seq_len, 156)


def assemble_seamless_pose(global_orient, body_pose, left_hand_pose, right_hand_pose):
    """ç»„è£…seamlesså§¿æ€å‘é‡ä¸ºè½´è§’è¡¨ç¤º"""
    return np.concatenate([
        global_orient,      # (N, 3)
        body_pose,         # (N, 63)
        left_hand_pose,     # (N, 45)
        right_hand_pose      # (N, 45)
    ], axis=1)  # (N, 156)


def split_to_body_parts(pose_6d, upper_mask, lower_mask, hand_mask):
    """å°†6Dè¡¨ç¤ºåˆ†å‰²ä¸ºä¸åŒèº«ä½“éƒ¨ä½"""
    return (
        pose_6d[:, upper_mask],  # ä¸ŠåŠèº« (N, 78)
        pose_6d[:, lower_mask],  # ä¸‹åŠèº« (N, 54)
        pose_6d[:, hand_mask]   # æ‰‹éƒ¨ (N, 180)
    )


def split_axis_angle_to_parts(poses_axis_angle, upper_joints, lower_joints, hand_joints):
    """å°†è½´è§’è¡¨ç¤ºåˆ†å‰²ä¸ºä¸åŒèº«ä½“éƒ¨ä½"""
    poses_reshaped = poses_axis_angle.reshape(-1, 52, 3)

    # ä¸ŠåŠèº«ï¼š13ä¸ªå…³èŠ‚ç‚¹
    upper_pose = poses_reshaped[:, upper_joints, :].reshape(-1, len(upper_joints)*3)

    # ä¸‹åŠèº«ï¼š9ä¸ªå…³èŠ‚ç‚¹
    lower_pose = poses_reshaped[:, lower_joints, :].reshape(-1, len(lower_joints)*3)

    # æ‰‹éƒ¨ï¼š30ä¸ªå…³èŠ‚ç‚¹
    hand_pose = poses_reshaped[:, hand_joints, :].reshape(-1, len(hand_joints)*3)

    return upper_pose, lower_pose, hand_pose


def reconstruct_full_motion(upper_rec, lower_rec, hands_rec,
                         upper_mask, lower_mask, hand_mask,
                         mean_pose, std_pose):
    """å°†ä¸‰ç§éƒ¨ä½é¢„æµ‹ç»“æœæ‹¼æ¥å¹¶åå½’ä¸€åŒ–"""
    seq_len = upper_rec.shape[0]

    # 1. åˆ›å»ºå®Œæ•´å§¿æ€å®¹å™¨
    full_pose = np.zeros((seq_len, 312))

    # 2. å°†å„éƒ¨ä½é¢„æµ‹ç»“æœå›å¡«
    full_pose[:, upper_mask] = upper_rec
    full_pose[:, lower_mask] = lower_rec
    full_pose[:, hand_mask] = hands_rec

    # 3. åå½’ä¸€åŒ–
    denormalized_pose = full_pose * std_pose + mean_pose

    return denormalized_pose


class RVQModelLoader:
    """RVQ-VAEæ¨¡å‹åŠ è½½å™¨"""

    def __init__(self, device='cuda:0'):
        self.device = device
        self.models = {}

    def load_model(self, model_path, body_part):
        """åŠ è½½æŒ‡å®šèº«ä½“éƒ¨ä½çš„æ¨¡å‹"""
        if body_part not in self.models:
            # æ ¹æ®èº«ä½“éƒ¨ä½è®¾ç½®å‚æ•°
            if body_part == 'upper':
                dim_pose = 13 * 6  # 78ç»´
                joints = [3, 6, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
            elif body_part == 'lower':
                dim_pose = 9 * 6   # 54ç»´
                joints = [0, 1, 2, 4, 5, 7, 8, 10, 11]
            elif body_part == 'hands':
                dim_pose = 30 * 6  # 180ç»´
                joints = list(range(22, 52))
            else:
                raise ValueError(f"æœªçŸ¥çš„èº«ä½“éƒ¨ä½: {body_part}")

            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            args = self._create_model_args()
            model = RVQVAE(args, dim_pose, args.nb_code, args.code_dim,
                          args.output_emb_width, args.down_t, args.stride_t,
                          args.width, args.depth, args.dilation_growth_rate,
                          args.vq_act, args.vq_norm)

            # åŠ è½½æƒé‡
            if os.path.exists(model_path):
                ckpt = torch.load(model_path, map_location='cpu')

                # æ£€æŸ¥checkpointä¸­çš„æ¨¡å‹å‚æ•°
                if 'net' in ckpt:
                    checkpoint_params = ckpt['net']
                else:
                    checkpoint_params = ckpt

                # å°è¯•ä½¿ç”¨strict=FalseåŠ è½½ï¼Œå…è®¸å‚æ•°ä¸åŒ¹é…
                try:
                    model.load_state_dict(checkpoint_params, strict=False)
                except Exception as e:
                    print(f"âš ï¸ æ¨¡å‹åŠ è½½è­¦å‘Š: {e}")
                    print("ğŸ”§ å°è¯•ä½¿ç”¨å®½æ¾æ¨¡å¼åŠ è½½...")
                    model.load_state_dict(checkpoint_params, strict=False)

                model.to(self.device)
                model.eval()
                self.models[body_part] = model
            else:
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {model_path}")

    def _create_model_args(self):
        """åˆ›å»ºæ¨¡å‹å‚æ•°å¯¹è±¡"""
        class Args:
            # å¿…éœ€çš„é‡åŒ–å‚æ•°
            num_quantizers = 6
            shared_codebook = False
            quantize_dropout_prob = 0.2

            # å¿…éœ€çš„æ¶æ„å‚æ•°
            mu = 0.99  # æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼Œç”¨äºä»£ç æœ¬æ›´æ–°
            nb_code = 2048  # ä»£ç æœ¬å¤§å°
            code_dim = 256  # ä»£ç ç»´åº¦ (ä¸ä¿å­˜çš„æ¨¡å‹åŒ¹é…)
            output_emb_width = 256  # è¾“å‡ºåµŒå…¥å®½åº¦
            down_t = 2  # ä¸‹é‡‡æ ·å±‚æ•°
            stride_t = 2  # æ—¶é—´æ­¥é•¿
            width = 512  # ç½‘ç»œå®½åº¦
            depth = 3  # ç½‘ç»œæ·±åº¦
            dilation_growth_rate = 3  # è†¨èƒ€å¢é•¿ç‡
            vq_act = 'relu'  # VQæ¿€æ´»å‡½æ•°
            vq_norm = None  # VQå½’ä¸€åŒ–
        return Args()


def process_sequence(data, model, device):
    """å¤„ç†ä»»æ„é•¿åº¦åºåˆ—æ•°æ®ï¼Œæ”¯æŒå®Œæ•´é•¿åº¦ä¸€æ¬¡æ€§æ¨ç†"""
    seq_len = data.shape[0]

    # ä¸€æ¬¡æ€§å¤„ç†å®Œæ•´åºåˆ—ï¼Œä¸åˆ†å—
    chunk_tensor = torch.from_numpy(data).float().unsqueeze(0).to(device)

    with torch.no_grad():
        result = model(chunk_tensor)
        rec_data = result['rec_pose']  # ç›´æ¥è·å–é‡æ„æ•°æ®
        return rec_data.squeeze(0).cpu().numpy()


def get_args_parser():
    """å‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(description='Seamlessæ•°æ®é›†è¿åŠ¨é‡å»ºæ¨ç†è„šæœ¬',
                                     add_help=True,
                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    # è¾“å…¥è¾“å‡ºå‚æ•°
    parser.add_argument('--input-npz', type=str, required=True,
                        help='è¾“å…¥è¿åŠ¨æ•°æ®NPZæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-npz', type=str, required=True,
                        help='è¾“å‡ºé‡å»ºåçš„è¿åŠ¨æ•°æ®NPZæ–‡ä»¶è·¯å¾„')

    # æ¨¡å‹è·¯å¾„å‚æ•°
    parser.add_argument('--upper-model', type=str,
                        default='outputs/rvq_seamless/seamless_144frame_1024batch_256dim_2048code_upper/net_best.pth',
                        help='ä¸ŠåŠèº«æ¨¡å‹è·¯å¾„')
    parser.add_argument('--lower-model', type=str,
                        default='outputs/rvq_seamless/seamless_144frame_1024batch_256dim_2048code_lower/net_best.pth',
                        help='ä¸‹åŠèº«æ¨¡å‹è·¯å¾„')
    parser.add_argument('--hands-model', type=str,
                        default='outputs/rvq_seamless/seamless_144frame_1024batch_256dim_2048code_hands/net_best.pth',
                        help='æ‰‹éƒ¨æ¨¡å‹è·¯å¾„')

    # å½’ä¸€åŒ–å‚æ•°
    parser.add_argument('--mean-pose', type=str,
                        default='./mean_std_seamless/seamless_2_312_mean.npy',
                        help='å§¿æ€å½’ä¸€åŒ–å‡å€¼æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--std-pose', type=str,
                        default='./mean_std_seamless/seamless_2_312_std.npy',
                        help='å§¿æ€å½’ä¸€åŒ–æ ‡å‡†å·®æ–‡ä»¶è·¯å¾„')

    # å…¶ä»–å‚æ•°
    parser.add_argument('--gpu-id', type=int, default=1,
                        help='GPUè®¾å¤‡ID')

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = get_args_parser()

    # è®¾ç½®æ—¥å¿—
    output_dir = os.path.dirname(args.output_npz)
    logger = setup_logger(output_dir)

    logger.info("="*60)
    logger.info("Seamlessæ•°æ®é›†è¿åŠ¨é‡å»ºæ¨ç†è„šæœ¬")
    logger.info("="*60)

    # 1. éªŒè¯è¾“å…¥æ–‡ä»¶
    logger.info(f"ğŸ“‚ éªŒè¯è¾“å…¥æ–‡ä»¶: {args.input_npz}")
    is_valid, input_data = validate_input_file(args.input_npz)
    if not is_valid:
        logger.error(f"âŒ è¾“å…¥æ–‡ä»¶éªŒè¯å¤±è´¥: {input_data}")
        return 1

    # 2. éªŒè¯æ¨¡å‹æ–‡ä»¶
    model_paths = {
        'upper': args.upper_model,
        'lower': args.lower_model,
        'hands': args.hands_model
    }
    logger.info("ğŸ” éªŒè¯æ¨¡å‹æ–‡ä»¶...")
    validate_models_exist(model_paths)

    # 3. åŠ è½½å½’ä¸€åŒ–å‚æ•°
    logger.info("ğŸ“Š åŠ è½½å½’ä¸€åŒ–å‚æ•°...")
    mean_pose = np.load(args.mean_pose)
    std_pose = np.load(args.std_pose)
    logger.info(f"   å‡å€¼å½¢çŠ¶: {mean_pose.shape}")
    logger.info(f"   æ ‡å·®å½¢çŠ¶: {std_pose.shape}")

    # 4. è®¾ç½®è®¾å¤‡
    device = torch.device(f'cuda:{args.gpu_id}' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ğŸ® ä½¿ç”¨è®¾å¤‡: {device}")

    # 5. åˆ›å»ºèº«ä½“éƒ¨ä½æ©ç 
    upper_joints = [3, 6, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]  # 13ä¸ªå…³èŠ‚ç‚¹
    lower_joints = [0, 1, 2, 4, 5, 7, 8, 10, 11]  # 9ä¸ªå…³èŠ‚ç‚¹
    hand_joints = list(range(22, 52))  # 30ä¸ªå…³èŠ‚ç‚¹

    upper_mask = [i*6 + j for i in upper_joints for j in range(6)]  # 78ç»´
    lower_mask = [i*6 + j for i in lower_joints for j in range(6)]  # 54ç»´
    hand_mask = [i*6 + j for i in hand_joints for j in range(6)]   # 180ç»´

    logger.info(f"ğŸ‘¤ èº«ä½“éƒ¨ä½åˆ†å‰²:")
    logger.info(f"   ä¸ŠåŠèº«: {len(upper_joints)}ä¸ªå…³èŠ‚, {len(upper_mask)}ç»´")
    logger.info(f"   ä¸‹åŠèº«: {len(lower_joints)}ä¸ªå…³èŠ‚, {len(lower_mask)}ç»´")
    logger.info(f"   æ‰‹éƒ¨: {len(hand_joints)}ä¸ªå…³èŠ‚, {len(hand_mask)}ç»´")

    # 6. åˆ›å»ºæ¨¡å‹åŠ è½½å™¨
    model_loader = RVQModelLoader(device)

    # 7. åŠ è½½ä¸‰ä¸ªæ¨¡å‹
    logger.info("ğŸš€ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...")
    model_loader.load_model(args.upper_model, 'upper')
    model_loader.load_model(args.lower_model, 'lower')
    model_loader.load_model(args.hands_model, 'hands')

    logger.info("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½å®Œæˆ")

    # 8. è¯»å–å¹¶å¤„ç†è¾“å…¥æ•°æ®
    logger.info("ğŸ“¥ è¯»å–å¹¶å¤„ç†è¾“å…¥æ•°æ®...")

    # è¯»å–NPZæ–‡ä»¶å­—æ®µ
    input_data = np.load(args.input_npz, allow_pickle=True)
    global_orient = input_data["smplh:global_orient"]  # (N, 3)
    body_pose = input_data["smplh:body_pose"].reshape(-1, 63)  # (N, 21, 3) -> (N, 63)
    left_hand_pose = input_data["smplh:left_hand_pose"].reshape(-1, 45)  # (N, 15, 3) -> (N, 45)
    right_hand_pose = input_data["smplh:right_hand_pose"].reshape(-1, 45)  # (N, 15, 3) -> (N, 45)
    translation = input_data["smplh:translation"]  # (N, 3)
    
    # å°†å¹³ç§»æ•°æ®ä»å˜ç±³è½¬æ¢ä¸ºç±³
    translation = translation / 100.0

    # ç»„è£…ä¸º156ç»´è½´è§’è¡¨ç¤º
    poses_axis_angle = assemble_seamless_pose(global_orient, body_pose, left_hand_pose, right_hand_pose)
    logger.info(f"   åŸå§‹æ•°æ®å½¢çŠ¶: {poses_axis_angle.shape}")

    # è½¬æ¢ä¸º6Dè¡¨ç¤ºå¹¶å½’ä¸€åŒ–
    poses_6d = axis_angle_to_6d(poses_axis_angle)
    normalized_poses = (poses_6d - mean_pose) / std_pose
    logger.info(f"   å½’ä¸€åŒ–åå½¢çŠ¶: {normalized_poses.shape}")

    # åˆ†å‰²ä¸ºä¸‰ä¸ªèº«ä½“éƒ¨ä½
    upper_data, lower_data, hands_data = split_to_body_parts(normalized_poses, upper_mask, lower_mask, hand_mask)

    logger.info(f"   ä¸ŠåŠèº«æ•°æ®: {upper_data.shape}")
    logger.info(f"   ä¸‹åŠèº«æ•°æ®: {lower_data.shape}")
    logger.info(f"   æ‰‹éƒ¨æ•°æ®: {hands_data.shape}")

    # 9. åˆ†åˆ«æ¨ç†ä¸‰ç§èº«ä½“éƒ¨ä½
    logger.info("ğŸ¤– å¼€å§‹æ¨¡å‹æ¨ç†...")

    with torch.no_grad():
        # ä¸ŠåŠèº«æ¨ç†
        upper_rec = process_sequence(upper_data, model_loader.models['upper'], device)

        # ä¸‹åŠèº«æ¨ç†
        lower_rec = process_sequence(lower_data, model_loader.models['lower'], device)

        # æ‰‹éƒ¨æ¨ç†
        hands_rec = process_sequence(hands_data, model_loader.models['hands'], device)

    logger.info("âœ… æ‰€æœ‰éƒ¨ä½æ¨ç†å®Œæˆ")

    # 10. é‡å»ºå®Œæ•´è¿åŠ¨æ•°æ®
    logger.info("ğŸ”— é‡å»ºå®Œæ•´è¿åŠ¨æ•°æ®...")

    reconstructed_6d = reconstruct_full_motion(
        upper_rec, lower_rec, hands_rec,
        upper_mask, lower_mask, hand_mask,
        mean_pose, std_pose
    )

    logger.info(f"   é‡å»ºåå½¢çŠ¶: {reconstructed_6d.shape}")

    # 11. è½¬æ¢å›è½´è§’è¡¨ç¤º
    reconstructed_axis_angle = d6_to_axis_angle(reconstructed_6d)
    logger.info(f"   è½´è§’è¡¨ç¤ºå½¢çŠ¶: {reconstructed_axis_angle.shape}")

    # 12. åˆ†å‰²å›åŸå§‹æ ¼å¼
    seq_len = reconstructed_axis_angle.shape[0]

    # æŒ‰ç…§SMPL-Xæ ‡å‡†æ ¼å¼åˆ†å‰²ï¼šglobal_orient(3) + body_pose(63) + left_hand_pose(45) + right_hand_pose(45)
    rec_global_orient = reconstructed_axis_angle[:, :3]  # (N, 3)
    rec_body_pose = reconstructed_axis_angle[:, 3:66].reshape(-1, 63)  # (N, 21, 3) -> (N, 63)
    rec_left_hand_pose = reconstructed_axis_angle[:, 66:111].reshape(-1, 45)  # (N, 15, 3) -> (N, 45)
    rec_right_hand_pose = reconstructed_axis_angle[:, 111:156].reshape(-1, 45)  # (N, 15, 3) -> (N, 45)
    rec_translation = translation  # ä¿æŒåŸå§‹å¹³ç§»ä¸å˜

    logger.info(f"   global_orientå½¢çŠ¶: {rec_global_orient.shape}")
    logger.info(f"   body_poseå½¢çŠ¶: {rec_body_pose.shape}")
    logger.info(f"   left_hand_poseå½¢çŠ¶: {rec_left_hand_pose.shape}")
    logger.info(f"   right_hand_poseå½¢çŠ¶: {rec_right_hand_pose.shape}")
    logger.info(f"   translationå½¢çŠ¶: {rec_translation.shape}")

    logger.info("ğŸ’¾ ä¿å­˜é‡å»ºç»“æœ...")

    # 13. ä¿å­˜ç»“æœ
    output_dir = os.path.dirname(args.output_npz)
    if output_dir:  # åªæœ‰å½“ç›®å½•ä¸ä¸ºç©ºæ—¶æ‰åˆ›å»º
        os.makedirs(output_dir, exist_ok=True)

    output_data = {
        "smplh:global_orient": rec_global_orient,
        "smplh:body_pose": rec_body_pose,
        "smplh:left_hand_pose": rec_left_hand_pose,
        "smplh:right_hand_pose": rec_right_hand_pose,
        "smplh:translation": rec_translation
    }

    # ä½¿ç”¨**kwargsæ–¹å¼ä¿å­˜ï¼Œé¿å…å­—å…¸å¯¹è±¡é—®é¢˜
    np.savez(args.output_npz, **output_data)
    logger.info(f"âœ… é‡å»ºå®Œæˆï¼ç»“æœä¿å­˜è‡³: {args.output_npz}")

    # 14. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    logger.info("="*60)
    logger.info("ğŸ“Š é‡å»ºç»Ÿè®¡ä¿¡æ¯:")
    logger.info(f"   è¾“å…¥åºåˆ—é•¿åº¦: {seq_len}")

    # è®¡ç®—å„éƒ¨ä½é‡å»ºè¯¯å·®
    upper_error = np.mean((upper_rec - upper_data)**2)
    lower_error = np.mean((lower_rec - lower_data)**2)
    hands_error = np.mean((hands_rec - hands_data)**2)

    logger.info(f"   ä¸ŠåŠèº«L2è¯¯å·®: {upper_error:.6f}")
    logger.info(f"   ä¸‹åŠèº«L2è¯¯å·®: {lower_error:.6f}")
    logger.info(f"   æ‰‹éƒ¨L2è¯¯å·®: {hands_error:.6f}")
    logger.info(f"   æ•´ä½“L2è¯¯å·®: {(upper_error + lower_error + hands_error):.6f}")

    return 0

if __name__ == "__main__":
    main()
    
# python seamless_motion_reconstruction.py --input-npz V00_S0080_I00000377_P0115.npz --output-npz recon_144_V00_S0080_I00000377_P0115.npz