#!/usr/bin/env python3
"""
RVQ-VAE Seamlessæ•°æ®é›†æ¨ç†è„šæœ¬

è¯¥è„šæœ¬ç”¨äºè°ƒç”¨è®­ç»ƒå¥½çš„RVQ-VAEæ¨¡å‹é‡å»ºSeamlessæ•°æ®é›†çš„NPZè¿åŠ¨æ•°æ®ã€‚
çº¯ç²¹ä¸“æ³¨äºæ¨ç†åŠŸèƒ½ï¼Œä¸åŒ…å«é¢å¤–çš„è¯„ä¼°å’Œå¯è§†åŒ–ã€‚

ä½¿ç”¨æ–¹å¼:
    # å•æ–‡ä»¶æ¨ç†
    python rvq_seamless_inference.py --model-path ./outputs/rvq_seamless/RVQVAE_Seamless_whole/net_best.pth --input-path ./datasets/seamless_interaction/improvised/session_0/gesture_001/frame_0000.npz --output-path ./reconstructed_motion.npz

    # æ‰¹é‡ç›®å½•æ¨ç†
    python rvq_seamless_inference.py --model-path ./outputs/rvq_seamless/RVQVAE_Seamless_whole/net_best.pth --input-path ./datasets/seamless_interaction/improvised/session_0/ --output-path ./reconstructed_results/
"""

import os
import sys
import json
import argparse
import numpy as np
import torch
import torch.nn as nn
from pathlib import Path
import glob
import pynvml
from utils import rotation_conversions as rc

# å¯¼å…¥æ¨¡å‹å’Œæ•°æ®é…ç½®
from models.vq.model import RVQVAE
from dataloaders.seamless_sep import CustomDataset
from omegaconf import OmegaConf

def setup_gpu(gpu_id):
    """è®¾ç½®GPUè®¾å¤‡"""
    if torch.cuda.is_available():
        torch.cuda.set_device(gpu_id)
        device = torch.device(f'cuda:{gpu_id}')
        print(f"ä½¿ç”¨GPU: {gpu_id}")
    else:
        device = torch.device('cpu')
        print("ä½¿ç”¨CPU")
    return device

def get_args_parser():
    """å‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description='RVQ-VAE Seamlessæ•°æ®é›†æ¨ç†è„šæœ¬',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    # å¿…è¦å‚æ•°
    parser.add_argument('--model-path', type=str, required=True,
                        help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„')
    parser.add_argument('--input-path', type=str, required=True,
                        help='è¾“å…¥NPZæ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--output-path', type=str, required=True,
                        help='è¾“å‡ºNPZæ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')

    # å¯é€‰å‚æ•°
    parser.add_argument('--body-part', type=str, default='whole',
                        choices=['whole', 'upper', 'lower', 'hands'],
                        help='èº«ä½“éƒ¨ä½é€‰æ‹©')
    parser.add_argument('--gpu-id', type=int, default=0,
                        help='GPUè®¾å¤‡ID')
    parser.add_argument('--batch-size', type=int, default=32,
                        help='æ¨ç†æ‰¹æ¬¡å¤§å°')

    return parser.parse_args()

def get_body_mask(body_part):
    """è·å–èº«ä½“éƒ¨ä½å…³èŠ‚æ©ç """
    if body_part == "upper":
        # ä¸ŠåŠèº«ï¼š13ä¸ªå…³èŠ‚ç‚¹
        joints = [3, 6, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
    elif body_part == "hands":
        # æ‰‹éƒ¨ï¼š30ä¸ªå…³èŠ‚ç‚¹ (22-51)
        joints = list(range(22, 52))
    elif body_part == "lower":
        # ä¸‹åŠèº«ï¼š9ä¸ªå…³èŠ‚ç‚¹
        joints = [0, 1, 2, 4, 5, 7, 8, 10, 11]
    elif body_part == "whole":
        # å…¨éƒ¨52ä¸ªå…³èŠ‚ç‚¹
        joints = list(range(52))
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„body_part: {body_part}")

    # æ„å»º6Dç»´åº¦æ©ç 
    body_mask = []
    for i in joints:
        body_mask.extend([i*6, i*6+1, i*6+2, i*6+3, i*6+4, i*6+5])

    return joints, body_mask

def load_model(model_path, device):
    """åŠ è½½é¢„è®­ç»ƒçš„RVQ-VAEæ¨¡å‹"""
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")

    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

    # åŠ è½½checkpoint
    ckpt = torch.load(model_path, map_location='cpu')

    # ä»checkpointä¸­è·å–æ¨¡å‹é…ç½®
    # å¦‚æœä¿å­˜æ—¶åŒ…å«argsï¼Œåˆ™ä½¿ç”¨ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    if 'args' in ckpt:
        args = ckpt['args']
    else:
        # ä½¿ç”¨è®­ç»ƒæ—¶çš„é»˜è®¤é…ç½®
        class DefaultArgs:
            def __init__(self):
                self.num_quantizers = 6
                self.shared_codebook = False
                self.quantize_dropout_prob = 0.0  # æ¨ç†æ—¶å…³é—­dropout

                # æ¨¡å‹æ¶æ„å‚æ•°ï¼ˆæ ¹æ®é”™è¯¯ä¿¡æ¯ä¿®æ­£ï¼‰
                self.code_dim = 128          # ä¿®æ­£ä¸º128
                self.output_emb_width = 128  # ä¿®æ­£ä¸º128
                self.down_t = 2
                self.stride_t = 2
                self.width = 512
                self.depth = 3
                self.dilation_growth_rate = 3
                self.vq_act = 'relu'
                self.vq_norm = None

                # EMAå‚æ•°
                self.mu = 0.99  # é»˜è®¤EMAæ›´æ–°ç‡

                # å…¶ä»–é‡åŒ–å™¨å‚æ•°
                self.nb_code = 1024  # ä»£ç æœ¬å¤§å°
                self.commit = 0.0     # æ¨ç†æ—¶ä¸éœ€è¦commitment loss

        args = DefaultArgs()

    # æ ¹æ®body_partè®¾ç½®è¾“å…¥ç»´åº¦
    dim_pose = len(ckpt.get('body_mask', range(52))) * 6  # é»˜è®¤ä½¿ç”¨å…¨éƒ¨52å…³èŠ‚çš„6Dè¡¨ç¤º

    # åˆ›å»ºæ¨¡å‹
    model = RVQVAE(
        args,
        input_width=dim_pose,
        nb_code=args.nb_code if hasattr(args, 'nb_code') else 1024,
        code_dim=args.code_dim,
        output_emb_width=args.output_emb_width,
        down_t=args.down_t,
        stride_t=args.stride_t,
        width=args.width,
        depth=args.depth,
        dilation_growth_rate=args.dilation_growth_rate,
        activation=args.vq_act,
        norm=args.vq_norm
    )

    # åŠ è½½æƒé‡
    if 'net' in ckpt:
        model.load_state_dict(ckpt['net'], strict=True)
    elif 'model_state_dict' in ckpt:
        model.load_state_dict(ckpt['model_state_dict'], strict=True)
    else:
        raise KeyError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æƒé‡é”®åï¼Œæ£€æŸ¥checkpointæ ¼å¼")

    model = model.to(device)
    model.eval()

    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    return model

def load_seamless_normalization():
    """åŠ è½½Seamlessæ•°æ®é›†çš„å½’ä¸€åŒ–å‚æ•°"""
    mean_pose_path = './mean_std_seamless/seamless_2_312_mean.npy'
    std_pose_path = './mean_std_seamless/seamless_2_312_std.npy'

    if not os.path.exists(mean_pose_path) or not os.path.exists(std_pose_path):
        raise FileNotFoundError("å½’ä¸€åŒ–æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿seamlessæ•°æ®é›†å½’ä¸€åŒ–æ–‡ä»¶åœ¨./mean_std_seamless/ç›®å½•ä¸‹")

    mean_pose = np.load(mean_pose_path)
    std_pose = np.load(std_pose_path)

    return mean_pose, std_pose

def process_npz_file(npz_path, joints, body_mask, device):
    """å¤„ç†å•ä¸ªNPZæ–‡ä»¶ï¼Œè½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼"""
    try:
        # åŠ è½½NPZæ–‡ä»¶
        pose_data = np.load(npz_path, allow_pickle=True)

        # æ£€æŸ¥å¿…è¦çš„å­—æ®µ
        required_fields = ["smplh:global_orient", "smplh:body_pose",
                          "smplh:left_hand_pose", "smplh:right_hand_pose"]

        for field in required_fields:
            if field not in pose_data:
                raise KeyError(f"NPZæ–‡ä»¶ä¸­ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")

        # æå–å§¿æ€æ•°æ®
        global_orient = pose_data["smplh:global_orient"]  # [N, 3]
        body_pose = pose_data["smplh:body_pose"]          # [N, 21, 3] -> [N, 63]
        left_hand_pose = pose_data["smplh:left_hand_pose"]  # [N, 15, 3] -> [N, 45]
        right_hand_pose = pose_data["smplh:right_hand_pose"] # [N, 15, 3] -> [N, 45]

        # é‡å¡‘ä¸º2D
        body_pose = body_pose.reshape(body_pose.shape[0], -1)
        left_hand_pose = left_hand_pose.reshape(left_hand_pose.shape[0], -1)
        right_hand_pose = right_hand_pose.reshape(right_hand_pose.shape[0], -1)

        # ç»„è£…å§¿æ€å‘é‡ [global_orient(3) + body(63) + left_hand(45) + right_hand(45)] = 156ç»´
        poses = np.concatenate([
            global_orient,      # 3ç»´
            body_pose,         # 63ç»´
            left_hand_pose,    # 45ç»´
            right_hand_pose    # 45ç»´
        ], axis=1)            # æ€»è®¡156ç»´

        # åˆ›å»ºå®Œæ•´çš„52å…³èŠ‚æ©ç æ˜ å°„
        # 52å…³èŠ‚å¯¹åº”å…³ç³»ï¼š
        # [0] global_orient
        # [1-21] body_pose (21ä¸ªå…³èŠ‚)
        # [22-36] left_hand_pose (15ä¸ªå…³èŠ‚)
        # [37-51] right_hand_pose (15ä¸ªå…³èŠ‚)

        # ä¸ºæ¯ä¸ªåŸå§‹ç»´åº¦æ‰¾åˆ°å¯¹åº”çš„è¾“å‡ºç»´åº¦
        output_indices = []
        for joint_idx in joints:
            if joint_idx == 0:  # global_orient
                output_indices.extend([0, 1, 2])  # 3ç»´
            elif 1 <= joint_idx <= 21:  # body_pose
                body_joint_idx = joint_idx - 1
                for dim in range(3):
                    output_indices.append(3 + body_joint_idx * 3 + dim)  # 3 + (joint_idx-1)*3
            elif 22 <= joint_idx <= 36:  # left_hand_pose
                hand_joint_idx = joint_idx - 22
                for dim in range(3):
                    output_indices.append(66 + hand_joint_idx * 3 + dim)  # 66 + (joint_idx-22)*3
            elif 37 <= joint_idx <= 51:  # right_hand_pose
                hand_joint_idx = joint_idx - 37
                for dim in range(3):
                    output_indices.append(111 + hand_joint_idx * 3 + dim)  # 111 + (joint_idx-37)*3

        # æå–å¯¹åº”çš„ç»´åº¦
        masked_poses = poses[:, output_indices]  # [N, len(joints)*3]

        print(f"æå–çš„å…³èŠ‚æ•°: {len(joints)}, ç»´åº¦: {masked_poses.shape}")

        # è½¬æ¢ä¸º6Dæ—‹è½¬è¡¨ç¤º
        poses_tensor = torch.from_numpy(masked_poses).float()
        n_frames = poses_tensor.shape[0]
        n_joints = len(joints)

        # é‡å¡‘ä¸º (N, J, 3) æ ¼å¼
        poses_3d = poses_tensor.reshape(n_frames, n_joints, 3)

        # è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
        poses_matrix = rc.axis_angle_to_matrix(poses_3d)

        # è½¬æ¢ä¸º6Dè¡¨ç¤º
        poses_6d = rc.matrix_to_rotation_6d(poses_matrix)

        # é‡å¡‘å› (N, J*6) æ ¼å¼
        poses_6d = poses_6d.reshape(n_frames, -1)  # [N, len(joints)*6]

        return poses_6d.numpy(), pose_data

    except Exception as e:
        print(f"å¤„ç†NPZæ–‡ä»¶æ—¶å‡ºé”™ {npz_path}: {str(e)}")
        return None, None

def inference_motion(model, motion_data, body_mask, mean_pose, std_pose, device, batch_size=32):
    """æ‰§è¡Œè¿åŠ¨æ¨ç†"""
    print(f"å¼€å§‹æ¨ç†ï¼Œè¾“å…¥å½¢çŠ¶: {motion_data.shape}")

    # åº”ç”¨å½’ä¸€åŒ–
    # motion_dataçš„ç»´åº¦åº”è¯¥æ˜¯ [N, len(joints)*6]ï¼Œéœ€è¦æ˜ å°„åˆ°312ç»´çš„å½’ä¸€åŒ–å‚æ•°
    mean_subset = mean_pose[body_mask]
    std_subset = std_pose[body_mask]
    motion_normalized = (motion_data - mean_subset) / std_subset

    # è½¬æ¢ä¸ºtensor
    motion_tensor = torch.from_numpy(motion_normalized).float().to(device)

    # ç¡®ä¿æ•°æ®ç»´åº¦æ­£ç¡® [seq_len, dim]
    if len(motion_tensor.shape) == 2:
        motion_tensor = motion_tensor.unsqueeze(0)  # [1, seq_len, dim]

    # åˆ†æ‰¹å¤„ç†é•¿åºåˆ—
    seq_len = motion_tensor.shape[1]
    dim = motion_tensor.shape[2]

    reconstructed_batches = []

    model.eval()
    with torch.no_grad():
        for start_idx in range(0, seq_len, batch_size):
            end_idx = min(start_idx + batch_size, seq_len)
            batch_data = motion_tensor[:, start_idx:end_idx, :]

            # æ¨¡å‹æ¨ç†
            output = model(batch_data)
            rec_motion = output['rec_pose']  # [1, batch_len, dim]

            reconstructed_batches.append(rec_motion.cpu().numpy())

    # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡
    reconstructed_motion = np.concatenate(reconstructed_batches, axis=1)  # [1, seq_len, dim]
    reconstructed_motion = reconstructed_motion.squeeze(0)  # [seq_len, dim]

    # åå½’ä¸€åŒ–
    mean_subset = mean_pose[body_mask]
    std_subset = std_pose[body_mask]
    reconstructed_motion = reconstructed_motion * std_subset + mean_subset

    print(f"âœ… æ¨ç†å®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {reconstructed_motion.shape}")

    return reconstructed_motion

def save_reconstructed_motion(rec_motion, original_data, output_path, joints, body_mask):
    """ä¿å­˜é‡å»ºçš„è¿åŠ¨æ•°æ®ä¸ºNPZæ ¼å¼"""
    try:
        # å°†6Dè¡¨ç¤ºè½¬æ¢å›è½´è§’è¡¨ç¤º
        rec_tensor = torch.from_numpy(rec_motion).float()
        n_frames = rec_tensor.shape[0]
        n_joints = len(joints)

        # é‡å¡‘ä¸º (N, J, 6) æ ¼å¼
        rec_6d = rec_tensor.reshape(n_frames, n_joints, 6)

        # ä»6Dè½¬æ¢å›æ—‹è½¬çŸ©é˜µ
        rec_matrix = rc.rotation_6d_to_matrix(rec_6d)

        # ä»æ—‹è½¬çŸ©é˜µè½¬æ¢å›è½´è§’
        rec_axis_angle = rc.matrix_to_axis_angle(rec_matrix)

        # é‡å¡‘å› (N, J*3) æ ¼å¼
        rec_axis_angle = rec_axis_angle.reshape(n_frames, -1).numpy()

        # é‡å»ºåŸå§‹156ç»´çš„å®Œæ•´å§¿æ€
        full_rec_poses = np.zeros((n_frames, 156))

        # å°†é‡å»ºçš„å…³èŠ‚æ•°æ®æ”¾å›æ­£ç¡®ä½ç½®
        for i, joint_idx in enumerate(joints):
            if joint_idx == 0:  # global_orient
                full_rec_poses[:, i*3:(i+1)*3] = rec_axis_angle[:, i*3:(i+1)*3]
            elif 1 <= joint_idx <= 21:  # body_pose
                full_rec_poses[:, 3 + (joint_idx-1)*3:3 + joint_idx*3] = rec_axis_angle[:, i*3:(i+1)*3]
            elif 22 <= joint_idx <= 36:  # left_hand_pose
                full_rec_poses[:, 66 + (joint_idx-22)*3:66 + (joint_idx-21)*3] = rec_axis_angle[:, i*3:(i+1)*3]
            elif 37 <= joint_idx <= 51:  # right_hand_pose
                full_rec_poses[:, 111 + (joint_idx-37)*3:111 + (joint_idx-36)*3] = rec_axis_angle[:, i*3:(i+1)*3]

        # åˆ†è§£å›åŸå§‹å­—æ®µ
        global_orient = full_rec_poses[:, :3]           # [N, 3]
        body_pose = full_rec_poses[:, 3:66]            # [N, 63] -> [N, 21, 3]
        left_hand_pose = full_rec_poses[:, 66:111]     # [N, 45] -> [N, 15, 3]
        right_hand_pose = full_rec_poses[:, 111:156]   # [N, 45] -> [N, 15, 3]

        # é‡å¡‘èº«ä½“éƒ¨ä½ä¸º3Dæ ¼å¼
        body_pose = body_pose.reshape(n_frames, 21, 3)
        left_hand_pose = left_hand_pose.reshape(n_frames, 15, 3)
        right_hand_pose = right_hand_pose.reshape(n_frames, 15, 3)

        # åˆ›å»ºè¾“å‡ºæ•°æ®å­—å…¸
        output_data = {}

        # é‡å»ºåçš„å§¿æ€æ•°æ®
        output_data["smplh:global_orient"] = global_orient
        output_data["smplh:body_pose"] = body_pose
        output_data["smplh:left_hand_pose"] = left_hand_pose
        output_data["smplh:right_hand_pose"] = right_hand_pose

        # ä¿ç•™å…¶ä»–åŸå§‹å­—æ®µï¼ˆå¦‚æœæœ‰ï¼‰
        if original_data is not None:
            for key, value in original_data.items():
                if key not in ["smplh:global_orient", "smplh:body_pose",
                              "smplh:left_hand_pose", "smplh:right_hand_pose"]:
                    output_data[key] = value

        # ä¿å­˜NPZæ–‡ä»¶
        np.savez_compressed(output_path, **output_data)

        print(f"âœ… é‡å»ºç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        return True

    except Exception as e:
        print(f"ä¿å­˜NPZæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    args = get_args_parser()

    # è®¾ç½®GPUè®¾å¤‡
    device = setup_gpu(args.gpu_id)

    # è·å–èº«ä½“éƒ¨ä½é…ç½®
    joints, body_mask = get_body_mask(args.body_part)
    print(f"èº«ä½“éƒ¨ä½: {args.body_part}, å…³èŠ‚æ•°é‡: {len(joints)}, ç»´åº¦: {len(body_mask)}")

    # åŠ è½½å½’ä¸€åŒ–å‚æ•°
    print("åŠ è½½å½’ä¸€åŒ–å‚æ•°...")
    mean_pose, std_pose = load_seamless_normalization()

    # åŠ è½½æ¨¡å‹
    model = load_model(args.model_path, device)

    # ç¡®å®šè¾“å…¥æ–‡ä»¶åˆ—è¡¨
    input_path = Path(args.input_path)
    if input_path.is_file() and input_path.suffix == '.npz':
        npz_files = [input_path]
    elif input_path.is_dir():
        npz_files = list(input_path.glob("**/*.npz"))
        print(f"æ‰¾åˆ° {len(npz_files)} ä¸ªNPZæ–‡ä»¶")
    else:
        raise FileNotFoundError(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸æ˜¯æœ‰æ•ˆçš„NPZæ–‡ä»¶: {args.input_path}")

    # è®¾ç½®è¾“å‡ºè·¯å¾„
    output_path = Path(args.output_path)
    if output_path.is_file() or (not output_path.exists() and input_path.is_file()):
        # å•æ–‡ä»¶è¾“å‡º
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_files = [output_path]
    else:
        # ç›®å½•è¾“å‡º
        output_path.mkdir(parents=True, exist_ok=True)
        output_files = []
        for npz_file in npz_files:
            rel_path = npz_file.relative_to(input_path)
            out_file = output_path / f"reconstructed_{rel_path.name}"
            output_files.append(out_file)

    # æ‰¹é‡å¤„ç†æ–‡ä»¶
    success_count = 0
    for i, (npz_file, out_file) in enumerate(zip(npz_files, output_files)):
        print(f"\nå¤„ç†æ–‡ä»¶ {i+1}/{len(npz_files)}: {npz_file}")

        # å¤„ç†NPZæ–‡ä»¶
        motion_data, original_data = process_npz_file(npz_file, joints, body_mask, device)
        if motion_data is None:
            print(f"è·³è¿‡æ–‡ä»¶ {npz_file}")
            continue

        # æ‰§è¡Œæ¨ç†
        reconstructed_motion = inference_motion(
            model, motion_data, body_mask, mean_pose, std_pose, device, args.batch_size
        )

        # ä¿å­˜ç»“æœ
        if save_reconstructed_motion(reconstructed_motion, original_data, out_file, joints, body_mask):
            success_count += 1

    print(f"\nğŸ‰ æ¨ç†å®Œæˆï¼æˆåŠŸå¤„ç† {success_count}/{len(npz_files)} ä¸ªæ–‡ä»¶")

if __name__ == "__main__":
    main()