wandb_project: 'GestureLSM'
exp_name: 'seamless_shortcut_rvqvae_128_simplify'

wandb_entity: 'xxxx'
wandb_key: "xxxxxxx"
wandb_log_dir: './outputs/wandb'
output_dir: ./outputs/weights
log_period: 10
val_period: 10 #20
gpus: [0,1,2,3,4,5]
seed: 0
ddp: true
debug: false

vqvae_upper_path: ./outputs/rvq_seamless/seamless_64frame_1024batch_128dim_1024code_upper/net_best.pth
vqvae_hands_path: ./outputs/rvq_seamless/seamless_64frame_1024batch_128dim_1024code_hands/net_best.pth
vqvae_lower_path: ./outputs/rvq_seamless/seamless_64frame_1024batch_128dim_1024code_lower_trans/net_best.pth



grad_ckpt: false # whether to use gradient checkpointing, for memory saving 原来是false


pre_frames: 4
pose_length: 128
vqvae_squeeze_scale: 4
vqvae_latent_scale: 5
vae_length: 240
vae_test_len: 32
mean_pose_path: "./mean_std_seamless/mean_pose.npy"
std_pose_path: "./mean_std_seamless/std_pose.npy"
mean_trans_path: "./mean_std_seamless/mean_trans.npy"
std_trans_path: "./mean_std_seamless/std_trans.npy"

data:
  name_pyfile: "dataloaders.seamless_interaction_dataset"
  class_name: "CustomDataset"
  train_bs: 128
  val_bs: 64 # 原来没有
  multi_length_training: [1.0]
  root_path: ./
  beat_align: True
  pose_rep: smplxflame_30
  
  pose_norm: True
  pose_fps: 30
  rot6d: True
  pose_dims: 825
  pose_length: 128
  stride: 60
  test_length: 128
  audio_sr: 16000
  audio_fps: 16000
  audio_norm: False
  
  data_path_1: ./datasets/hub/
  data_path: ./datasets/seamless_interaction/improvised/
  # training_speakers: [2]
  additional_data: False
  cache_path: ./datasets/seamless_cache/seamless_smplx_128/
  new_cache: False
  disable_filtering: False
  clean_first_seconds: 0
  clean_final_seconds: 0

  audio_rep: onset+amplitude
  word_rep: json #textgrid
  t_pre_encoder: fasttext
  facial_rep: null #smplxflame_30
  id_rep: null #onehot
  emo_rep: null
  sem_rep: null
  test_clip: False
  onset_rep: True

model:
  model_name: LSM
  g_name: GestureLSM
  do_classifier_free_guidance: False
  guidance_scale: 2
  n_steps: 2
  use_exp: False

  denoiser:
    target: models.denoiser.GestureDenoiser
    params:
      input_dim: 128
      latent_dim: 256
      ff_size: 1024
      num_layers: 8
      num_heads: 4
      dropout: 0.1 #0.1
      activation: "gelu"
      n_seed: 8
      seq_len: 32
      flip_sin_to_cos: True
      freq_shift: 0.0
      cond_proj_dim: 256
      use_exp: ${model.use_exp}
  
  modality_encoder:
    target: models.layers.modality_encoder.ModalityEncoder
    params:
      data_path: ./datasets/seamless_interaction/improvised/
      t_fix_pre: False
      audio_dim: 256
      audio_in: 2
      raw_audio: False
      latent_dim: 256
      audio_fps: 30
      target_length: 128
      spatial_temporal: True
      use_exp: ${model.use_exp}

 
validation:
  val_loss_steps: 200
  validation_steps: 1000

solver:
  opt: 'adam'
  epochs: 1000 #1000
  grad_norm: 1.0
  momentum: 0.8
  nesterov: True
  amsgrad: False
  
  # lr
  lr_base: 1e-5 #2e-4
  lr_policy: 'step'
  decay_rate: 0.1
  lr_warmup_steps: 50
  decay_epochs: 500
  warmup_epochs: 0
  warmup_lr: 1e-6 #5e-4
  lr_min: 1e-7
  weight_decay: 0.0
  opt_betas: [0.5, 0.999]




