wandb_project: 'GestureLSM'
exp_name: 'shortcut_rvqvae_128_mfcc_1'

wandb_entity: 'xxxx'
wandb_key: "xxxxxxx"
wandb_log_dir: './outputs/wandb'
output_dir: ./outputs/weights
log_period: 10
val_period: 20
gpus: [0,1,2,3]
seed: 42 #42
ddp: true
debug: false

vqvae_upper_path: ./ckpt/net_300000_upper.pth
vqvae_hands_path: ./ckpt/net_300000_hands.pth
vqvae_lower_path: ./ckpt/net_300000_lower.pth



grad_ckpt: false # whether to use gradient checkpointing, for memory saving


pre_frames: 4
pose_length: 128
vqvae_squeeze_scale: 4
vqvae_latent_scale: 5 #5
vae_length: 240
vae_test_len: 32
mean_pose_path: "./mean_std/beatx_2_330_mean.npy"
std_pose_path: "./mean_std/beatx_2_330_std.npy"
mean_trans_path: "./mean_std/beatx_2_trans_mean.npy"
std_trans_path: "./mean_std/beatx_2_trans_std.npy"

data:
  name_pyfile: "dataloaders.beat_sep_lower"
  class_name: "CustomDataset"
  train_bs: 128
  multi_length_training: [1.0]
  root_path: ./
  beat_align: True
  pose_rep: smplxflame_30
  
  pose_norm: True
  pose_fps: 30
  rot6d: True
  pose_dims: 825
  pose_length: 128
  stride: 20
  test_length: 128
  audio_sr: 16000
  audio_fps: 100 #16000
  audio_norm: False
  
  data_path_1: ./datasets/hub/
  data_path: ./datasets/BEAT_SMPL/beat_v2.0.0/beat_english_v2.0.0/
  training_speakers: [2] # [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 30] # [2]
  additional_data: False
  cache_path: ./datasets/beat_cache/beat_smplx_en_emage_6_128_mfcc/
  new_cache: False
  disable_filtering: False
  clean_first_seconds: 0
  clean_final_seconds: 0

  audio_rep: mfcc #onset+amplitude
  word_rep: textgrid
  t_pre_encoder: fasttext
  facial_rep: null #smplxflame_30
  id_rep: null #onehot
  emo_rep: null
  sem_rep: null
  test_clip: False
  onset_rep: True

model:
  model_name: LSM
  g_name: GestureLSM
  do_classifier_free_guidance: True #False
  guidance_scale: 2 #2
  n_steps: 2
  use_exp: False
  # ID embedding configuration
  use_id: false
  max_id: 100  # 预留足够的ID空间
  id_embedding_dim: 256  # 与denoiser潜在维度保持一致

  denoiser:
    target: models.denoiser.GestureDenoiser
    params:
      input_dim: 128
      latent_dim: 256
      ff_size: 1024
      num_layers: 8
      num_heads: 4
      dropout: 0.1 #0.1
      activation: "gelu"
      n_seed: 8
      seq_len: 32
      flip_sin_to_cos: True
      freq_shift: 0.0
      cond_proj_dim: 256 # 256 (audio) + 256 (ID embedding)
      use_exp: ${model.use_exp}
      # Add ID-related parameters
      use_id: ${model.use_id}
      id_embedding_dim: ${model.id_embedding_dim}
  
  modality_encoder:
    target: models.layers.modality_encoder.ModalityEncoder
    params:
      data_path: ./datasets/BEAT_SMPL/beat_v2.0.0/beat_english_v2.0.0/
      vocab_path: ./datasets/unified_vocab.pkl
      t_fix_pre: False
      audio_dim: 256
      audio_in: 128 #2
      raw_audio: False
      latent_dim: 256
      audio_fps: 100 #30
      target_length: 128
      spatial_temporal: True
      use_exp: ${model.use_exp}

 
validation:
  val_loss_steps: 200
  validation_steps: 1000

solver:
  opt: 'adam'
  epochs: 1000 #1000
  grad_norm: 1.0
  momentum: 0.8
  nesterov: True
  amsgrad: False
  
  # lr
  lr_base: 1e-5 #2e-4
  lr_policy: 'step'
  decay_rate: 0.1
  lr_warmup_steps: 50
  decay_epochs: 500
  warmup_epochs: 100 #0
  warmup_lr: 1e-6 #5e-4
  lr_min: 1e-7
  weight_decay: 0.0
  opt_betas: [0.5, 0.999]
  # Early stopping configuration
  early_stopping:
    enabled: true
    patience: 5
    delta: 0.001




