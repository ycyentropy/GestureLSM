#!/usr/bin/env python3
"""
æœ€å°åŒ–è®­ç»ƒæµ‹è¯•ï¼Œæ‰¾å‡ºå¡ä½çš„ç¡®åˆ‡ä½ç½®
"""

import sys
import os
sys.path.append('/home/embodied/yangchenyu/GestureLSM')

import torch
import numpy as np
from torch.utils.data import DataLoader
from lazy_window_dataset import CachedLazySeamlessInteractionWindowDataset
from models.vq.model import RVQVAE
import time

def minimal_train_test():
    print("=== æœ€å°åŒ–è®­ç»ƒæµ‹è¯• ===")

    # 1. åˆ›å»ºæ•°æ®é›†
    print("\n1. åˆ›å»ºæ•°æ®é›†...")
    dataset = CachedLazySeamlessInteractionWindowDataset(
        data_path="/home/embodied/yangchenyu/GestureLSM/datasets/seamless_interaction",
        split="train",
        window_size=64,
        window_stride=20,
        multi_length_training=[1.0],  # åªç”¨å•é•¿åº¦é¿å…å¤æ‚æ€§
        load_video=False,
        load_audio=False,
        max_samples=10,  # åªç”¨10ä¸ªæ ·æœ¬
        cache_path="datasets/window_params/window_params_train_ws64_ws20_fixed.pkl"
    )
    print(f"âœ“ æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œé•¿åº¦: {len(dataset)}")

    # 2. åˆ›å»ºDataLoader
    print("\n2. åˆ›å»ºDataLoader...")
    def simple_collate_fn(batch):
        max_len = max(item['pose'].shape[0] for item in batch)
        batch_size = len(batch)
        pose_dim = batch[0]['pose'].shape[1]

        poses = torch.zeros(batch_size, max_len, pose_dim)
        for i, item in enumerate(batch):
            pose = item['pose']
            length = pose.shape[0]
            poses[i, :length] = pose

        return {'pose': poses, 'mask': torch.ones(batch_size, max_len, dtype=torch.bool)}

    dataloader = DataLoader(
        dataset,
        batch_size=2,
        shuffle=False,
        num_workers=0,
        drop_last=True,
        collate_fn=simple_collate_fn
    )
    print(f"âœ“ DataLoaderåˆ›å»ºæˆåŠŸï¼Œé•¿åº¦: {len(dataloader)}")

    # 3. åˆ›å»ºæ¨¡å‹
    print("\n3. åˆ›å»ºæ¨¡å‹...")
    class Args:
        def __init__(self):
            self.code_dim = 128
            self.down_t = 2
            self.stride_t = 2
            self.width = 512
            self.depth = 3
            self.dilation_growth_rate = 3
            self.vq_act = 'relu'
            self.vq_norm = None
            self.num_quantizers = 8
            self.nb_code = 1024
            self.commit = 0.02
            self.mu = 0.99
            self.quantize_dropout_prob = 0.5
            self.recons_loss = 'l1_smooth'
            self.loss_vel = 0.0
            self.shared_codebook = False

    args = Args()
    model = RVQVAE(
        args,
        156,  # input_dim
        args.nb_code,
        args.code_dim,
        args.code_dim,
        args.down_t,
        args.stride_t,
        args.width,
        args.depth,
        args.dilation_growth_rate,
        args.vq_act,
        args.vq_norm
    )

    device = torch.device("cuda:0")
    model.to(device)
    model.train()
    print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°é‡: {sum(p.numel() for p in model.parameters())/1e6:.1f}M")

    # 4. åŠ è½½å‡å€¼æ ‡å‡†å·®
    print("\n4. åŠ è½½å‡å€¼æ ‡å‡†å·®...")
    mean_pose = np.load('mean_std/seamless_smplh_mean.npy')
    std_pose = np.load('mean_std/seamless_smplh_std.npy')
    print(f"âœ“ å‡å€¼æ ‡å‡†å·®åŠ è½½æˆåŠŸï¼Œå½¢çŠ¶: {mean_pose.shape}")

    # 5. åˆ›å»ºä¼˜åŒ–å™¨
    print("\n5. åˆ›å»ºä¼˜åŒ–å™¨...")
    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)
    print("âœ“ ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")

    # 6. è®­ç»ƒå¾ªç¯æµ‹è¯•
    print("\n6. å¼€å§‹è®­ç»ƒå¾ªç¯æµ‹è¯•...")

    max_iter = 3
    for iter_num in range(max_iter):
        print(f"\n--- è¿­ä»£ {iter_num + 1}/{max_iter} ---")

        # 6.1 è·å–æ•°æ®æ‰¹æ¬¡
        print("6.1 è·å–æ•°æ®æ‰¹æ¬¡...")
        start_time = time.time()

        try:
            for batch in dataloader:
                batch_time = time.time()
                print(f"âœ“ æ‰¹æ¬¡è·å–æˆåŠŸï¼Œè€—æ—¶: {batch_time - start_time:.2f}ç§’")
                break
        except Exception as e:
            print(f"âœ— æ‰¹æ¬¡è·å–å¤±è´¥: {e}")
            return

        # 6.2 æ•°æ®ç§»åˆ°GPU
        print("6.2 æ•°æ®ç§»åˆ°GPU...")
        try:
            gt_motion = batch['pose'].to(device)
            batch_mask = batch['mask'].to(device)
            print(f"âœ“ æ•°æ®ç§»åˆ°GPUæˆåŠŸï¼Œå½¢çŠ¶: {gt_motion.shape}")
        except Exception as e:
            print(f"âœ— æ•°æ®ç§»åˆ°GPUå¤±è´¥: {e}")
            return

        # 6.3 æ•°æ®æ ‡å‡†åŒ–
        print("6.3 æ•°æ®æ ‡å‡†åŒ–...")
        try:
            mean_pose_tensor = torch.from_numpy(mean_pose[:156]).to(device)
            std_pose_tensor = torch.from_numpy(std_pose[:156]).to(device)
            mean_pose_tensor = mean_pose_tensor.unsqueeze(0).unsqueeze(0)
            std_pose_tensor = std_pose_tensor.unsqueeze(0).unsqueeze(0)
            gt_motion = (gt_motion - mean_pose_tensor) / std_pose_tensor
            print("âœ“ æ•°æ®æ ‡å‡†åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âœ— æ•°æ®æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return

        # 6.4 å‰å‘ä¼ æ’­
        print("6.4 å‰å‘ä¼ æ’­...")
        try:
            pred_motion, loss_commit, perplexity = model(gt_motion).values()
            print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
        except Exception as e:
            print(f"âœ— å‰å‘ä¼ æ’­å¤±è´¥: {e}")
            return

        # 6.5 è®¡ç®—æŸå¤±
        print("6.5 è®¡ç®—æŸå¤±...")
        try:
            loss_motion = torch.nn.functional.l1_loss(pred_motion, gt_motion)
            loss = loss_motion + args.commit * loss_commit
            print(f"âœ“ æŸå¤±è®¡ç®—æˆåŠŸ: {loss.item():.5f}")
        except Exception as e:
            print(f"âœ— æŸå¤±è®¡ç®—å¤±è´¥: {e}")
            return

        # 6.6 åå‘ä¼ æ’­
        print("6.6 åå‘ä¼ æ’­...")
        try:
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            print("âœ“ åå‘ä¼ æ’­æˆåŠŸ")
        except Exception as e:
            print(f"âœ— åå‘ä¼ æ’­å¤±è´¥: {e}")
            return

        print(f"âœ… è¿­ä»£ {iter_num + 1} å®Œæˆ")

    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è®­ç»ƒæµç¨‹æ­£å¸¸ã€‚")

if __name__ == "__main__":
    minimal_train_test()