#!/usr/bin/env python3
"""
æµ‹è¯•seamlessæ•°æ®é›†å¤šé•¿åº¦è®­ç»ƒé€»è¾‘
éªŒè¯ [0.5, 1.0, 1.5, 2.0] é…ç½®æ˜¯å¦æ­£ç¡®å·¥ä½œ
"""

import sys
import os
sys.path.append('.')

import numpy as np
import torch
from omegaconf import OmegaConf
from dataloaders.seamless_sep import CustomDataset
from utils import config

def test_multi_length_training():
    print("=" * 70)
    print("æµ‹è¯•å¤šé•¿åº¦è®­ç»ƒé€»è¾‘ [0.5, 1.0, 1.5, 2.0]")
    print("=" * 70)

    # åŠ è½½é…ç½®
    cfg = OmegaConf.load('./configs/seamless_rvqvae.yaml')

    class Args:
        def __init__(self, cfg_dict):
            for key, value in cfg_dict.items():
                setattr(self, key, value)

    args = Args(dict(cfg))

    # å¤šé•¿åº¦è®­ç»ƒé…ç½®
    multi_lengths = args.multi_length_training
    base_length = args.pose_length
    base_stride = args.stride
    pose_fps = args.pose_fps

    print(f"åŸºç¡€é…ç½®:")
    print(f"  åŸºç¡€é•¿åº¦: {base_length} å¸§")
    print(f"  åŸºç¡€æ­¥é•¿: {base_stride} å¸§")
    print(f"  å¸§ç‡: {pose_fps} FPS")
    print(f"  å¤šé•¿åº¦é…ç½®: {multi_lengths}")

    print(f"\nå¤šé•¿åº¦è®­ç»ƒè¯¦æƒ…:")
    total_samples_per_ratio = {}

    for i, ratio in enumerate(multi_lengths):
        length = int(base_length * ratio)
        stride = int(base_stride * ratio)
        time_sec = length / pose_fps

        print(f"  æ¯”ä¾‹ {ratio}:")
        print(f"    åºåˆ—é•¿åº¦: {length} å¸§ â‰ˆ {time_sec:.1f} ç§’")
        print(f"    æ­¥é•¿: {stride} å¸§")

        total_samples_per_ratio[ratio] = {
            'length': length,
            'stride': stride,
            'time_sec': time_sec
        }

    # æ¨¡æ‹Ÿé‡‡æ ·é€»è¾‘
    print(f"\næ¨¡æ‹Ÿæ•°æ®é‡‡æ ·é€»è¾‘:")

    # å‡è®¾æœ‰ä¸€ä¸ª1000å¸§çš„åºåˆ—
    total_frames = 1000
    clean_frames = total_frames  # ç®€åŒ–å‡è®¾ï¼Œä¸è€ƒè™‘æ¸…ç†

    print(f"  å‡è®¾æ€»å¸§æ•°: {total_frames} å¸§ â‰ˆ {total_frames/pose_fps:.1f} ç§’")

    for ratio in multi_lengths:
        length = int(base_length * ratio)
        stride = int(base_stride * ratio)

        # è®¡ç®—å¯ä»¥é‡‡æ ·å¤šå°‘ä¸ªç‰‡æ®µ
        num_samples = max(0, (clean_frames - length) // stride + 1)
        total_time = num_samples * (length / pose_fps)

        print(f"  æ¯”ä¾‹ {ratio}:")
        print(f"    å¯é‡‡æ ·ç‰‡æ®µæ•°: {num_samples}")
        print(f"    æ€»è®­ç»ƒæ—¶é—´: {total_time:.1f} ç§’")

    # æµ‹è¯•æ•°æ®é›†åˆå§‹åŒ–æ—¶çš„å¤šé•¿åº¦è®¾ç½®
    print(f"\néªŒè¯æ•°æ®é›†åˆå§‹åŒ–:")

    # è®¾ç½®å¿…è¦çš„å‚æ•°
    args.disable_filtering = True
    args.clean_first_seconds = 0
    args.clean_final_seconds = 0
    args.test_length = 128
    args.audio_sr = 16000
    args.audio_fps = 16000
    args.audio_rep = 'onset+amplitude'
    args.beat_align = False

    try:
        # åˆ›å»ºè®­ç»ƒé›†æ•°æ®é›†
        print(f"  åˆ›å»ºè®­ç»ƒé›†...")
        train_dataset = CustomDataset(args, "train", build_cache=False)
        print(f"  âœ“ è®­ç»ƒé›†åˆ›å»ºæˆåŠŸï¼Œæ‰¾åˆ° {len(train_dataset.selected_files)} ä¸ªæ–‡ä»¶")

        # åˆ›å»ºæµ‹è¯•é›†æ•°æ®é›†
        print(f"  åˆ›å»ºæµ‹è¯•é›†...")
        test_dataset = CustomDataset(args, "test", build_cache=False)
        print(f"  âœ“ æµ‹è¯•é›†åˆ›å»ºæˆåŠŸï¼Œæ‰¾åˆ° {len(test_dataset.selected_files)} ä¸ªæ–‡ä»¶")

        # éªŒè¯æµ‹è¯•é›†çš„å¤šé•¿åº¦è®¾ç½®
        print(f"  æµ‹è¯•é›†å¤šé•¿åº¦é…ç½®: {test_dataset.args.multi_length_training}")
        if test_dataset.args.multi_length_training == [1.0]:
            print(f"  âœ“ æµ‹è¯•é›†æ­£ç¡®è®¾ç½®ä¸ºå•ä¸€é•¿åº¦ [1.0]")
        else:
            print(f"  âœ— æµ‹è¯•é›†å¤šé•¿åº¦é…ç½®é”™è¯¯")

    except Exception as e:
        print(f"  âœ— æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
        return False

    print(f"\n" + "=" * 70)
    print("å¤šé•¿åº¦è®­ç»ƒé€»è¾‘éªŒè¯é€šè¿‡ï¼")
    print("=" * 70)

    return True

def test_memory_usage_estimation():
    """ä¼°ç®—ä¸åŒé•¿åº¦çš„å†…å­˜ä½¿ç”¨"""
    print(f"\nå†…å­˜ä½¿ç”¨ä¼°ç®—:")

    pose_dims = 312  # 52å…³èŠ‚ Ã— 6D
    trans_dims = 3
    facial_dims = 100
    total_dims = pose_dims + trans_dims + facial_dims  # 415ç»´

    batch_size = 64
    multi_lengths = [0.5, 1.0, 1.5, 2.0]
    base_length = 128
    pose_fps = 30

    print(f"  æ¯ä¸ªæ ·æœ¬ç»´åº¦: {total_dims} (å§¿æ€: {pose_dims}, å¹³ç§»: {trans_dims}, é¢éƒ¨: {facial_dims})")
    print(f"  æ‰¹æ¬¡å¤§å°: {batch_size}")

    for ratio in multi_lengths:
        length = int(base_length * ratio)
        # å‡è®¾float32ï¼Œæ¯ä¸ªå…ƒç´ 4å­—èŠ‚
        memory_mb = batch_size * length * total_dims * 4 / (1024 * 1024)

        print(f"  æ¯”ä¾‹ {ratio} ({length}å¸§ â‰ˆ {length/pose_fps:.1f}ç§’): ~{memory_mb:.1f} MB")

    print(f"  å»ºè®®GPUå†…å­˜: è‡³å°‘ {batch_size * 256 * total_dims * 4 / (1024 * 1024):.0f} MB")

def test_stride_consistency():
    """æµ‹è¯•æ­¥é•¿ä¸é•¿åº¦çš„ä¸€è‡´æ€§"""
    print(f"\næ­¥é•¿ä¸€è‡´æ€§æ£€æŸ¥:")

    base_length = 128
    base_stride = 20
    multi_lengths = [0.5, 1.0, 1.5, 2.0]

    for ratio in multi_lengths:
        length = int(base_length * ratio)
        stride = int(base_stride * ratio)

        # æ£€æŸ¥æ­¥é•¿æ˜¯å¦åˆç†ï¼ˆä¸åº”è¯¥è¶…è¿‡åºåˆ—é•¿åº¦ï¼‰
        if stride > length:
            print(f"  âš ï¸  æ¯”ä¾‹ {ratio}: æ­¥é•¿ {stride} > åºåˆ—é•¿åº¦ {length}ï¼Œå¯èƒ½å¯¼è‡´é‡‡æ ·é—®é¢˜")
        else:
            print(f"  âœ“ æ¯”ä¾‹ {ratio}: æ­¥é•¿ {stride} <= åºåˆ—é•¿åº¦ {length}")

        # æ£€æŸ¥è¦†ç›–ç‡
        coverage = stride / length
        print(f"    è¦†ç›–ç‡: {coverage:.2f} (æ­¥é•¿/åºåˆ—é•¿åº¦)")

if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯•Seamlesså¤šé•¿åº¦è®­ç»ƒé€»è¾‘...")

    # æµ‹è¯•å¤šé•¿åº¦è®­ç»ƒ
    multi_ok = test_multi_length_training()

    # æµ‹è¯•å†…å­˜ä¼°ç®—
    test_memory_usage_estimation()

    # æµ‹è¯•æ­¥é•¿ä¸€è‡´æ€§
    test_stride_consistency()

    if multi_ok:
        print(f"\nğŸ‰ å¤šé•¿åº¦è®­ç»ƒé€»è¾‘éªŒè¯æˆåŠŸï¼")
        print(f"   é…ç½® [0.5, 1.0, 1.5, 2.0] å·¥ä½œæ­£å¸¸")
        print(f"   æ”¯æŒä»2.1ç§’åˆ°8.5ç§’çš„å¤šæ ·åŒ–æ‰‹åŠ¿åºåˆ—")
        sys.exit(0)
    else:
        print(f"\nâŒ å¤šé•¿åº¦è®­ç»ƒé€»è¾‘éªŒè¯å¤±è´¥ï¼")
        sys.exit(1)