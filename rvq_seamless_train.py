import pynvml
from utils import rotation_conversions as rc

import os
import json
import argparse
import numpy as np

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
import logging
import sys
from dataloaders import data_tools
from utils import config, logger_tools, other_tools, metric
import numpy as np

import warnings
warnings.filterwarnings('ignore')
from models.vq.model import RVQVAE

# è®¾ç½®ä¸´æ—¶ç›®å½•åˆ°æœ‰å……è¶³ç©ºé—´çš„åˆ†åŒº
temp_dir = '/home/embodied/yangchenyu/tmp'
os.makedirs(temp_dir, exist_ok=True)
os.environ['TMPDIR'] = temp_dir
os.environ['TEMP'] = temp_dir
os.environ['TMP'] = temp_dir

# é˜²æ­¢è¢«å½“ä½œé…ç½®æ–‡ä»¶è§£æ
if __name__ != "__main__":
    print("This script should be executed directly, not imported.")
    print("Usage: python rvq_seamless_train.py [options]")
    sys.exit(1)

def get_logger(out_dir):
    logger = logging.getLogger('Exp')
    logger.setLevel(logging.INFO)
    formatter = logging.Formatter("%(asctime)s %(levelname)s %(message)s")

    file_path = os.path.join(out_dir, "run.log")
    file_hdlr = logging.FileHandler(file_path)
    file_hdlr.setFormatter(formatter)

    strm_hdlr = logging.StreamHandler(sys.stdout)
    strm_hdlr.setFormatter(formatter)

    logger.addHandler(file_hdlr)
    logger.addHandler(strm_hdlr)
    return logger

class ReConsLoss(nn.Module):
    def __init__(self, recons_loss):
        super(ReConsLoss, self).__init__()

        if recons_loss == 'l1':
            self.Loss = torch.nn.L1Loss()
        elif recons_loss == 'l2' :
            self.Loss = torch.nn.MSELoss()
        elif recons_loss == 'l1_smooth' :
            self.Loss = torch.nn.SmoothL1Loss()

    def my_forward(self,motion_pred,motion_gt,mask) :
        loss = self.Loss(motion_pred[..., mask], motion_gt[..., mask])
        return loss

    def velocity_loss(self, motion_pred, motion_gt, mask):
        """è®¡ç®—é€Ÿåº¦æŸå¤±ï¼Œæƒ©ç½šç›¸é‚»å¸§é—´çš„ä¸è¿ç»­å˜åŒ–"""
        if len(motion_pred.shape) < 3:
            return torch.tensor(0.0, device=motion_pred.device)

        # è®¡ç®—é¢„æµ‹é€Ÿåº¦å’ŒçœŸå®é€Ÿåº¦ï¼ˆæ—¶é—´å·®åˆ†ï¼‰
        if motion_pred.shape[1] > 1:  # ç¡®ä¿åºåˆ—é•¿åº¦è¶³å¤Ÿè®¡ç®—å·®åˆ†
            pred_vel = torch.diff(motion_pred, dim=1)  # [batch, seq_len-1, dim]
            gt_vel = torch.diff(motion_gt, dim=1)      # [batch, seq_len-1, dim]

            # åº”ç”¨æ©ç  (maskæ˜¯listæˆ–arrayï¼Œéœ€è¦è½¬æ¢ä¸ºtensor)
            if isinstance(mask, (list, np.ndarray)):
                mask_tensor = torch.tensor(mask, device=motion_pred.device, dtype=torch.long)
                pred_vel = pred_vel[..., mask_tensor]
                gt_vel = gt_vel[..., mask_tensor]

            # è®¡ç®—é€Ÿåº¦æŸå¤±
            vel_loss = self.Loss(pred_vel, gt_vel)
        else:
            vel_loss = torch.tensor(0.0, device=motion_pred.device)

        return vel_loss

    def jitter_loss(self, motion_pred, motion_gt, mask):
        """è®¡ç®—jitteræŸå¤±ï¼Œç›´æ¥ä¼˜åŒ–æŠ–åŠ¨é—®é¢˜

        ç›¸æ¯”é€Ÿåº¦æŸå¤±ï¼ŒjitteræŸå¤±æ›´ç›´æ¥åœ°æƒ©ç½šï¼š
        1. åŠ é€Ÿåº¦çš„äºŒé˜¶å·®åˆ†ï¼ˆå‡å°‘çªå…€çš„å˜åŒ–ï¼‰
        2. é«˜é¢‘æˆåˆ†ï¼ˆå‡å°‘å¿«é€ŸæŠ–åŠ¨ï¼‰
        3. è¿ç»­æ€§çº¦æŸï¼ˆé¼“åŠ±å¹³æ»‘è¿‡æ¸¡ï¼‰
        """
        if len(motion_pred.shape) < 3:
            return torch.tensor(0.0, device=motion_pred.device)

        if motion_pred.shape[1] <= 2:  # éœ€è¦è‡³å°‘3å¸§è®¡ç®—äºŒé˜¶å·®åˆ†
            return torch.tensor(0.0, device=motion_pred.device)

        # åº”ç”¨æ©ç 
        if isinstance(mask, (list, np.ndarray)):
            mask_tensor = torch.tensor(mask, device=motion_pred.device, dtype=torch.long)
            motion_pred_masked = motion_pred[..., mask_tensor]
            motion_gt_masked = motion_gt[..., mask_tensor]
        else:
            motion_pred_masked = motion_pred
            motion_gt_masked = motion_gt

        # 1. é€Ÿåº¦åŒ¹é…æŸå¤± - ä¸GTé€Ÿåº¦ä¿æŒä¸€è‡´
        pred_vel = torch.diff(motion_pred_masked, dim=1)  # [batch, seq_len-1, dim]
        gt_vel = torch.diff(motion_gt_masked, dim=1)      # [batch, seq_len-1, dim]
        vel_match = torch.mean((pred_vel - gt_vel)**2)

        # 2. åŠ é€Ÿåº¦åŒ¹é…æŸå¤± - ä¸GTåŠ é€Ÿåº¦ä¿æŒä¸€è‡´
        pred_accel = torch.diff(motion_pred_masked, n=2, dim=1)  # [batch, seq_len-2, dim]
        gt_accel = torch.diff(motion_gt_masked, n=2, dim=1)      # [batch, seq_len-2, dim]
        accel_match = torch.mean((pred_accel - gt_accel)**2)

        # ç»¼åˆjitteræŸå¤± - é€Ÿåº¦å’ŒåŠ é€Ÿåº¦éƒ½ä¸çœŸå€¼æ¯”è¾ƒ
        jitter_loss = (
            0.6 * vel_match +        # é€Ÿåº¦åŒ¹é… (40%)
            0.4 * accel_match      # åŠ é€Ÿåº¦åŒ¹é… (40%)
        )

        return jitter_loss

import argparse

def get_args_parser():
    parser = argparse.ArgumentParser(description='RVQ-VAE training for Seamless dataset',
                                     add_help=True,
                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    ## dataloader
    parser.add_argument('--dataname', type=str, default='seamless', help='dataset directory')
    parser.add_argument('--batch-size', default=4096, type=int, help='batch size')
    parser.add_argument('--window-size', type=int, default=64, help='training motion length')
    parser.add_argument('--body_part',type=str,default='whole', help='body part: whole, upper, lower, lower_trans, hands')
    ## optimization
    parser.add_argument('--total-iter', default=50000, type=int, help='number of total iterations to run')
    parser.add_argument('--warm-up-iter', default=1000, type=int, help='number of total iterations for warmup')
    parser.add_argument('--lr', default=1e-5, type=float, help='max learning rate')
    parser.add_argument('--lr-scheduler', default=[30000, 40000], nargs="+", type=int, help="learning rate schedule (iterations)")
    parser.add_argument('--gamma', default=0.1, type=float, help="learning rate decay")

    parser.add_argument('--weight-decay', default=0.0, type=float, help='weight decay')
    parser.add_argument("--commit", type=float, default=0.2, help="hyper-parameter for the commitment loss")
    # parser.add_argument('--loss-vel', type=float, default=0.1, help='hyper-parameter for the velocity loss')
    # parser.add_argument('--use-jitter-loss', action='store_true', help='use jitter loss instead of velocity loss for better smoothness')
    parser.add_argument('--recons-loss', type=str, default='l1_smooth', help='reconstruction loss')

    ## vqvae arch
    parser.add_argument("--code-dim", type=int, default=128, help="embedding dimension")
    parser.add_argument("--nb-code", type=int, default=1024, help="nb of embedding")
    parser.add_argument("--mu", type=float, default=0.99, help="exponential moving average to update the codebook")
    parser.add_argument("--down-t", type=int, default=2, help="downsampling rate")
    parser.add_argument("--stride-t", type=int, default=2, help="stride size")
    parser.add_argument("--width", type=int, default=512, help="width of the network")
    parser.add_argument("--depth", type=int, default=3, help="depth of the network")
    parser.add_argument("--dilation-growth-rate", type=int, default=3, help="dilation growth rate")
    parser.add_argument("--output-emb-width", type=int, default=512, help="output embedding width")
    parser.add_argument('--vq-act', type=str, default='relu', choices = ['relu', 'silu', 'gelu'], help='dataset directory')
    parser.add_argument('--vq-norm', type=str, default=None, help='dataset directory')

    ## quantizer
    parser.add_argument("--quantizer", type=str, default='ema_reset', choices = ['ema', 'orig', 'ema_reset', 'reset'], help="eps for optimal transport")
    parser.add_argument('--beta', type=float, default=1.0, help='commitment loss in standard VQ')

    ## resume
    parser.add_argument("--resume-pth", type=str, default=None, help='resume pth for VQ')
    parser.add_argument("--resume-gpt", type=str, default=None, help='resume pth for GPT')


    ## output directory
    parser.add_argument('--out-dir', type=str, default='outputs/rvq_seamless', help='output directory')
    parser.add_argument('--results-dir', type=str, default='visual_results/', help='output directory')
    parser.add_argument('--visual-name', type=str, default='seamless_baseline', help='output directory')
    parser.add_argument('--exp-name', type=str, default='RVQVAE_Seamless', help='name of the experiment, will create a file inside out-dir')
    ## other
    parser.add_argument('--print-iter', default=100, type=int, help='print frequency')
    parser.add_argument('--eval-iter', default=1000, type=int, help='evaluation frequency')
    parser.add_argument('--seed', default=0, type=int, help='123 seed for initializing training.')

    parser.add_argument('--vis-gt', action='store_true', help='whether visualize GT motions')
    parser.add_argument('--nb-vis', default=20, type=int, help='nb of visualizations')
    parser.add_argument('--mode', type=str, default='train', help='train or eval')
    parser.add_argument('--rebuild-cache', action='store_true', help='force rebuild cache even if exists')
    parser.add_argument('--cache-only', action='store_true', help='only build cache, do not train')
    parser.add_argument('--gpu-id', type=int, default=0, help='GPU ID to use for training')


    return parser.parse_args()

def update_lr_warm_up(optimizer, nb_iter, warm_up_iter, lr):

    current_lr = lr * (nb_iter + 1) / (warm_up_iter + 1)
    for param_group in optimizer.param_groups:
        param_group["lr"] = current_lr

    return optimizer, current_lr

##### ---- Exp dirs ---- #####
args = get_args_parser()

# è®¾ç½®GPUè®¾å¤‡
device = torch.device(f'cuda:{args.gpu_id}' if torch.cuda.is_available() else 'cpu')
torch.cuda.set_device(args.gpu_id)
torch.cuda.manual_seed(args.seed)
torch.manual_seed(args.seed)

args.out_dir = os.path.join(args.out_dir, f'{args.exp_name}_{args.body_part}')
os.makedirs(args.out_dir, exist_ok = True)

##### ---- Logger ---- #####
logger = get_logger(args.out_dir)
writer = SummaryWriter(args.out_dir)
logger.info(f"ä½¿ç”¨GPUè®¾å¤‡: {device}")
logger.info(json.dumps(vars(args), indent=4, sort_keys=True))

##### ---- Dataloader ---- #####
from dataloaders.seamless_sep import CustomDataset
from omegaconf import OmegaConf

# ç›´æ¥ä½¿ç”¨OmegaConfåŠ è½½é…ç½®ï¼Œé¿å…utils.configçš„å‚æ•°è§£æé—®é¢˜
cfg = OmegaConf.load("configs/seamless_rvqvae_train.yaml")
dataset_args = cfg

# è®¾ç½®ç¼“å­˜é€‰é¡¹
if args.rebuild_cache:
    dataset_args.new_cache = True
    logger.info("ğŸ”„ å¼ºåˆ¶é‡å»ºç¼“å­˜æ¨¡å¼å·²å¯ç”¨")
else:
    dataset_args.new_cache = False

logger.info("="*60)
logger.info("å¼€å§‹æ„å»ºSeamlessæ•°æ®é›†ç¼“å­˜...")
logger.info(f"æ•°æ®é›†è·¯å¾„: {dataset_args.data_path}")
logger.info(f"ç¼“å­˜è·¯å¾„: {dataset_args.cache_path}")
logger.info(f"å¤šé•¿åº¦è®­ç»ƒ: {dataset_args.multi_length_training}")
logger.info(f"å¼ºåˆ¶é‡å»ºç¼“å­˜: {args.rebuild_cache}")
logger.info("="*60)

# æ„å»ºè®­ç»ƒé›†ç¼“å­˜
logger.info("ğŸ”„ æ­£åœ¨æ„å»ºè®­ç»ƒé›†ç¼“å­˜...")
trainSet = CustomDataset(dataset_args,"train",build_cache = True)
logger.info(f"âœ… è®­ç»ƒé›†ç¼“å­˜æ„å»ºå®Œæˆï¼æ ·æœ¬æ•°é‡: {len(trainSet.selected_files)}")

# æ„å»ºæµ‹è¯•é›†ç¼“å­˜
logger.info("ğŸ”„ æ­£åœ¨æ„å»ºæµ‹è¯•é›†ç¼“å­˜...")
testSet = CustomDataset(dataset_args,"val",build_cache = True)
logger.info(f"âœ… æµ‹è¯•é›†ç¼“å­˜æ„å»ºå®Œæˆï¼æ ·æœ¬æ•°é‡: {len(testSet.selected_files)}")

# å¦‚æœåªæ˜¯æ„å»ºç¼“å­˜ï¼Œåˆ™ç›´æ¥é€€å‡º
if args.cache_only:
    logger.info("ğŸ¯ ç¼“å­˜æ„å»ºå®Œæˆï¼Œç¨‹åºé€€å‡ºï¼ˆ--cache-only æ¨¡å¼ï¼‰")
    sys.exit(0)

logger.info("="*60)
logger.info("ç¼“å­˜æ„å»ºå®Œæˆï¼Œå¼€å§‹åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
logger.info("="*60)

train_loader = torch.utils.data.DataLoader(trainSet,
                                              args.batch_size,
                                              shuffle=True,
                                              num_workers=2,
                                              drop_last = True,
                                              persistent_workers=True)
test_loader = torch.utils.data.DataLoader(testSet,
                                          1,
                                            shuffle=False,
                                            num_workers=0,
                                            drop_last = True)

def cycle(iterable):
    while True:
        for x in iterable:
            yield x

train_loader_iter = cycle(train_loader)
test_loader_iter = cycle(test_loader)

##### ---- Seamless Joint Masks ---- #####
if args.body_part == "upper":
    # ä¸ŠåŠèº«ï¼š13ä¸ªå…³èŠ‚ç‚¹
    joints = [3, 6, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
    upper_body_mask = []
    for i in joints:
        upper_body_mask.extend([i*6, i*6+1, i*6+2, i*6+3, i*6+4, i*6+5])
    mask = upper_body_mask
    rec_mask = list(range(len(mask)))

elif args.body_part == "hands":
    # æ‰‹éƒ¨ï¼š30ä¸ªå…³èŠ‚ç‚¹ (22-51) ,ä¿®æ”¹äº†ä¸€ä¸‹ï¼Œä»25å¼€å§‹
    # joints = list(range(25, 55))
    joints = list(range(22, 52))
    hands_body_mask = []
    for i in joints:
        hands_body_mask.extend([i*6, i*6+1, i*6+2, i*6+3, i*6+4, i*6+5])
    mask = hands_body_mask
    rec_mask = list(range(len(mask)))

elif args.body_part == "lower":
    # ä¸‹åŠèº«ï¼š9ä¸ªå…³èŠ‚ç‚¹
    joints = [0, 1, 2, 4, 5, 7, 8, 10, 11]
    lower_body_mask = []
    for i in joints:
        lower_body_mask.extend([i*6, i*6+1, i*6+2, i*6+3, i*6+4, i*6+5])
    mask = lower_body_mask
    rec_mask = list(range(len(mask)))

elif args.body_part == "lower_trans":
    # ä¸‹åŠèº«å¸¦å¹³ç§»ï¼š9ä¸ªå…³èŠ‚ç‚¹ + 3ä¸ªå¹³ç§»ç»´åº¦
    joints = [0, 1, 2, 4, 5, 7, 8, 10, 11]
    lower_body_mask = []
    for i in joints:
        lower_body_mask.extend([i*6, i*6+1, i*6+2, i*6+3, i*6+4, i*6+5])
    lower_body_mask.extend([330, 331, 332])  # æ·»åŠ å¹³ç§»ç»´åº¦
    mask = lower_body_mask
    rec_mask = list(range(len(mask)))

elif args.body_part == "whole":
    # å…¨éƒ¨52ä¸ªå…³èŠ‚ç‚¹ æ³¨æ„æˆ‘åœ¨è¿™é‡Œè¿›è¡Œäº†ä¿®æ”¹ï¼Œå°†22-55çš„å…³èŠ‚ç‚¹ç©ºç¼ºï¼Œåªä¿ç•™0-21å’Œ25-54
    # joints = list(range(0,22))+list(range(25,55))
    joints = list(range(0,52))
    whole_body_mask = []
    for i in joints:
        whole_body_mask.extend([i*6, i*6+1, i*6+2, i*6+3, i*6+4, i*6+5])
    mask = whole_body_mask
    rec_mask = list(range(len(mask)))

logger.info(f"Body part: {args.body_part}, Joint count: {len(joints)}, Mask dimensions: {len(mask)}")

##### ---- Model Configuration ---- #####
if args.body_part == "upper":
    dim_pose = len(joints) * 6   # 13 * 6 = 78
elif args.body_part == "hands":
    dim_pose = len(joints) * 6   # 30 * 6 = 180
elif args.body_part == "lower":
    dim_pose = len(joints) * 6   # 9 * 6 = 54
elif args.body_part == "lower_trans":
    dim_pose = len(joints) * 6 + 3  # 9 * 6 + 3 = 57 (åŒ…å«å¹³ç§»ç»´åº¦)
elif args.body_part == "whole":
    dim_pose = len(joints) * 6   # 52 * 6 = 312

args.num_quantizers = 6
args.shared_codebook = False
args.quantize_dropout_prob = 0.2

net = RVQVAE(args,
            dim_pose,
            args.nb_code,
            args.code_dim,
            args.code_dim,
            args.down_t,
            args.stride_t,
            args.width,
            args.depth,
            args.dilation_growth_rate,
            args.vq_act,
            args.vq_norm)

if args.resume_pth :
    logger.info('loading checkpoint from {}'.format(args.resume_pth))
    ckpt = torch.load(args.resume_pth, map_location='cpu')
    net.load_state_dict(ckpt['net'], strict=True)

##### ---- Seamless Normalization ---- #####
# ä½¿ç”¨seamlessæ•°æ®é›†çš„å½’ä¸€åŒ–æ–‡ä»¶
mean_pose_path = './mean_std_seamless/mean_pose.npy'
std_pose_path = './mean_std_seamless/std_pose.npy'

mean_pose = np.load(mean_pose_path)
std_pose = np.load(std_pose_path)

# è£å‰ªåˆ°å¯¹åº”çš„èº«ä½“éƒ¨ä½
# mean_pose = torch.from_numpy(mean_pose[mask]).to(device)
# std_pose = torch.from_numpy(std_pose[mask]).to(device)
mean_pose = torch.from_numpy(mean_pose).to(device)
std_pose = torch.from_numpy(std_pose).to(device)

logger.info(f"Loaded normalization: mean_pose.shape={mean_pose.shape}, std_pose.shape={std_pose.shape}")

##### ---- Evaluation Model for FID ---- #####
eval_model_module = __import__(f"models.motion_representation", fromlist=["something"])
args.vae_layer = 4
args.vae_length = 240
args.vae_test_dim = 330
args.variational = False
args.data_path_1 = "./datasets/hub/"
args.vae_grow = [1,1,2,1]
eval_copy = getattr(eval_model_module, 'VAESKConv')(args).to('cuda')
other_tools.load_checkpoints(eval_copy, './datasets/BEAT_SMPL/beat_v2.0.0/beat_english_v2.0.0/'+'weights/AESKConv_240_100.bin', 'VAESKConv')
eval_copy.eval()

if args.mode == 'train':
    net.train()
    net.to(device)

    ##### ---- Optimizer & Scheduler ---- #####
    optimizer = optim.AdamW(net.parameters(), lr=args.lr, betas=(0.9, 0.99), weight_decay=args.weight_decay)
    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=args.lr_scheduler, gamma=args.gamma)

    Loss = ReConsLoss(args.recons_loss)

    ##### ------ warm-up ------- #####
    avg_recons, avg_perplexity, avg_commit, avg_velocity = 0., 0., 0., 0.

    logger.info(f"Starting warm-up for {args.warm_up_iter} iterations...")

    for nb_iter in range(1, args.warm_up_iter):

        optimizer, current_lr = update_lr_warm_up(optimizer, nb_iter, args.warm_up_iter, args.lr)

        gt_motion = next(train_loader_iter)
        
        # # æ‰“å°å¤„ç†å‰åçš„æ•°æ®ç»´åº¦
        # print(f"[DEBUG] åŸå§‹gt_motionç»´åº¦: {gt_motion.shape}")
        
        gt_motion = gt_motion[...,mask].to(device).float() # (bs, 64, dim)
        
        # print(f"[DEBUG] åº”ç”¨maskågt_motionç»´åº¦: {gt_motion.shape}")
        # print(f"[DEBUG] maské•¿åº¦: {len(mask)}, maskå†…å®¹: {mask[:10]}...{mask[-10:]}")

        pred_motion, loss_commit, perplexity = net(gt_motion).values()
        
        # # æ‰“å°ç½‘ç»œè¾“å‡ºå€¼
        # # åªæœ‰å½“loss_commitå¤§äº1æ—¶æ‰æ‰“å°
        # if loss_commit.item() > 1:
        #     print(f"[DEBUG] loss_commitå€¼: {loss_commit.item()}")
        #     # è®¡ç®—æœ€åä¸‰ä¸ªç´¢å¼•çš„å‡å€¼
        #     mean_last_three = gt_motion[..., -3:].mean()
        #     print(f"[DEBUG] æœ€åä¸‰ä¸ªç´¢å¼•çš„å‡å€¼: {mean_last_three.item()}")
        #     # è®¡ç®—æ¯ä¸ªç´¢å¼•çš„å‡å€¼
        #     for i in range(3):
        #         idx = -3 + i
        #         mean_idx = gt_motion[..., idx].mean()
        #         print(f"[DEBUG] ç´¢å¼• {idx} çš„å‡å€¼: {mean_idx.item()}")
        loss_motion = Loss.my_forward(pred_motion, gt_motion,rec_mask)
        # é€‰æ‹©æŸå¤±å‡½æ•°ç±»å‹ - æš‚æ—¶æ³¨é‡Šæ‰jitterå’ŒvelocityæŸå¤±
        # if args.use_jitter_loss:
        #     loss_vel = Loss.jitter_loss(pred_motion, gt_motion, rec_mask)
        # else:
        #     loss_vel = Loss.velocity_loss(pred_motion, gt_motion, rec_mask)
        loss_vel = torch.tensor(0.0, device=loss_motion.device)

        loss = loss_motion + args.commit * loss_commit

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        avg_recons += loss_motion.item()
        avg_perplexity += perplexity.item()
        avg_commit += loss_commit.item()
        avg_velocity += loss_vel.item()

        if nb_iter % args.print_iter ==  0 :
            avg_recons /= args.print_iter
            avg_perplexity /= args.print_iter
            avg_commit /= args.print_iter
            avg_velocity /= args.print_iter

            # loss_type_name = "Jitter" if args.use_jitter_loss else "Velocity" - æš‚æ—¶æ³¨é‡Šæ‰jitterå’ŒvelocityæŸå¤±ç›¸å…³çš„æ—¥å¿—
            logger.info(f"Warmup. Iter {nb_iter} :  lr {current_lr:.7f} 	 Commit. {avg_commit:.5f} 	 PPL. {avg_perplexity:.2f} 	 Recons.  {avg_recons:.5f}")

            avg_recons, avg_perplexity, avg_commit, avg_velocity = 0., 0., 0., 0.

    ##### ---- Training ---- #####
    avg_recons, avg_perplexity, avg_commit, avg_velocity = 0., 0., 0., 0.

    logger.info(f"Starting main training for {args.total_iter} iterations...")

    best_l2 = 10000
    best_fid = 10000
    l2_history = []
    fid_history = []
    early_stop_patience = 5
    early_stop_counter = 0

    for nb_iter in range(1, args.total_iter + 1):

        gt_motion = next(train_loader_iter)
        gt_motion = gt_motion[...,mask].to(device).float() # bs, nb_joints, joints_dim, seq_len

        pred_motion, loss_commit, perplexity = net(gt_motion).values()
        loss_motion = Loss.my_forward(pred_motion, gt_motion,rec_mask)
        # é€‰æ‹©æŸå¤±å‡½æ•°ç±»å‹ - æš‚æ—¶æ³¨é‡Šæ‰jitterå’ŒvelocityæŸå¤±
        # if args.use_jitter_loss:
        #     loss_vel = Loss.jitter_loss(pred_motion, gt_motion, rec_mask)
        # else:
        #     loss_vel = Loss.velocity_loss(pred_motion, gt_motion, rec_mask)
        loss_vel = torch.tensor(0.0, device=loss_motion.device)

        loss = loss_motion + args.commit * loss_commit

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        scheduler.step()

        avg_recons += loss_motion.item()
        avg_perplexity += perplexity.item()
        avg_commit += loss_commit.item()
        avg_velocity += loss_vel.item()

        if nb_iter % args.print_iter ==  0 :
            avg_recons /= args.print_iter
            avg_perplexity /= args.print_iter
            avg_commit /= args.print_iter
            avg_velocity /= args.print_iter

            writer.add_scalar('./Train/L1', avg_recons, nb_iter)
            writer.add_scalar('./Train/PPL', avg_perplexity, nb_iter)
            writer.add_scalar('./Train/Commit', avg_commit, nb_iter)

            # loss_type_name = "Jitter" if args.use_jitter_loss else "Velocity" - æš‚æ—¶æ³¨é‡Šæ‰jitterå’ŒvelocityæŸå¤±ç›¸å…³çš„æ—¥å¿—
            logger.info(f"Train. Iter {nb_iter} : 	 Commit. {avg_commit:.5f} 	 PPL. {avg_perplexity:.2f} 	 Recons.  {avg_recons:.5f}")

            avg_recons, avg_perplexity, avg_commit, avg_velocity = 0., 0., 0., 0.,

        # ç®€åŒ–è¯„ä¼° - åªä½¿ç”¨L2è·ç¦»
        if nb_iter % args.eval_iter==0 :
            torch.save({'net' : net.state_dict()}, os.path.join(args.out_dir, f'net_{nb_iter}.pth'))

            net.eval()

            total_length = 0
            l2_all = 0
            lvel = 0

            logger.info(f"Evaluating at iteration {nb_iter}...")

            latent_out = []
            latent_ori = []
            diffs = []

            with torch.no_grad():
                for its, batch_data in enumerate(test_loader):
                    gt_motion = batch_data.to(device).float()
                    n = gt_motion.shape[1]
                    remain = n%8

                    if remain != 0:
                        gt_motion = gt_motion[:, :-remain, :]

                    gt_ori = gt_motion.clone()
                    gt_motion = gt_motion[...,mask] # (bs, 64, dim)
                    bs = gt_motion.shape[0]
                    pred_motion, loss_commit, perplexity = net(gt_motion).values()
                    diff = pred_motion - gt_motion

                    # pred_motion = pred_motion
                    rec_motion = gt_ori.clone()

                    rec_motion[..., mask] = pred_motion # it is already a 6d tensor

                    n = rec_motion.shape[1]

                    # ç®€åŒ–é‡å»º - åªåº”ç”¨åå½’ä¸€åŒ–åˆ°æ©ç éƒ¨åˆ†
                    rec_motion_part = rec_motion[..., :-103] * std_pose + mean_pose #æŠŠmaskæ”¹æˆ:-103
                    gt_motion_part = gt_ori[..., :-103] * std_pose + mean_pose

                    # è®¡ç®—L2è·ç¦»
                    l2_batch = torch.sqrt(torch.sum(diff ** 2, dim=[1, 2])).mean().item()
                    l2_all += l2_batch

                    # æ”¶é›†æ½œåœ¨è¡¨ç¤ºç”¨äºFIDè®¡ç®—
                    remain = n % 32
                    latent_out.append(eval_copy.map2latent(rec_motion_part[:, :n-remain]).reshape(-1, 32).detach().cpu().numpy())
                    latent_ori.append(eval_copy.map2latent(gt_motion_part[:, :n-remain]).reshape(-1, 32).detach().cpu().numpy())
                    diffs.append(diff[:, :n-remain].reshape(-1, 32).detach().cpu().numpy())

                latent_out_all = np.concatenate(latent_out, axis=0)
                latent_ori_all = np.concatenate(latent_ori, axis=0)
                diffs_all = np.concatenate(diffs, axis=0)

                fid = data_tools.FIDCalculator.frechet_distance(latent_out_all, latent_ori_all)
                logger.info(f"FID: {fid:.6f}")

                avg_l2 = l2_all / len(test_loader)
                logger.info(f"Iteration {nb_iter}: L2 distance: {avg_l2:.6f}")

                # Add current L2 to history
                l2_history.append(avg_l2)
                fid_history.append(fid)

                # Check for early stopping
                if len(l2_history) > early_stop_patience:
                    if best_l2 <= min(l2_history[-early_stop_patience:]) and best_fid <= min(fid_history[-early_stop_patience:]):
                        early_stop_counter += 1
                        logger.info(f"Early stopping counter: {early_stop_counter}/{early_stop_patience}")
                        if early_stop_counter >= early_stop_patience:
                            logger.info(f"Early stopping triggered at iteration {nb_iter}")
                            break
                    else:
                        early_stop_counter = 0

                # æ ¹æ® L2 ä¿å­˜æœ€ä½³æ¨¡å‹
                if avg_l2 < best_l2:
                    best_l2 = avg_l2
                    torch.save({'net' : net.state_dict()}, os.path.join(args.out_dir, 'net_best_l2.pth'))
                    logger.info(f"New best L2: {best_l2:.6f} - saved best model (L2)")

                # æ ¹æ® FID ä¿å­˜æœ€ä½³æ¨¡å‹
                if fid < best_fid:
                    best_fid = fid
                    torch.save({'net' : net.state_dict()}, os.path.join(args.out_dir, 'net_best_fid.pth'))
                    logger.info(f"New best FID: {best_fid:.6f} - saved best model (FID)")

                # è®°å½•L2å†å²
                import matplotlib.pyplot as plt
                # plt.figure()
                # iterations = list(range(len(l2_history)))
                # iterations = [x * args.eval_iter for x in iterations]
                # plt.plot(iterations, l2_history, label='L2 Distance')
                # plt.xlabel('Iteration')
                # plt.ylabel('L2 Distance')
                # plt.title('L2 Distance over Iterations')
                # plt.legend()
                # plt.savefig(os.path.join(args.out_dir, 'l2_plot.png'))
                # plt.close()

                # # è®°å½•FIDå†å²
                # plt.figure()
                # iterations = list(range(len(fid_history)))
                # iterations = [x * args.eval_iter for x in iterations]
                # plt.plot(iterations, fid_history, label='FID', color='orange')
                # plt.xlabel('Iteration')
                # plt.ylabel('FID')
                # plt.title('FID over Iterations')
                # plt.legend()
                # plt.savefig(os.path.join(args.out_dir, 'fid_plot.png'))
                # plt.close()

                # è®°å½•L2å’ŒFIDå¯¹æ¯”å†å²
                plt.figure()
                iterations = list(range(len(l2_history)))
                iterations = [x * args.eval_iter for x in iterations]
                fig, ax1 = plt.subplots()
                ax1.set_xlabel('Iteration')
                ax1.set_ylabel('L2 Distance', color='tab:blue')
                ax1.plot(iterations, l2_history, color='tab:blue', label='L2 Distance')
                ax1.tick_params(axis='y', labelcolor='tab:blue')
                ax2 = ax1.twinx()
                ax2.set_ylabel('FID', color='tab:orange')
                ax2.plot(iterations, fid_history, color='tab:orange', label='FID')
                ax2.tick_params(axis='y', labelcolor='tab:orange')
                plt.title('L2 Distance and FID over Iterations')
                fig.tight_layout()
                plt.savefig(os.path.join(args.out_dir, 'l2_fid_plot.png'))
                plt.close()

            net.train()

    logger.info("Training completed!")
    logger.info(f"Best L2 distance achieved: {best_l2:.6f}")

else:
    logger.info("Evaluation mode - loading model...")
    net.eval()
    net.to(device)

    if args.resume_pth:
        logger.info('loading checkpoint from {}'.format(args.resume_pth))
        ckpt = torch.load(args.resume_pth, map_location='cpu')
        net.load_state_dict(ckpt['net'], strict=True)

    total_length = 0
    l2_all = 0
    lvel = 0

    logger.info("Running evaluation...")

    latent_out = []
    latent_ori = []
    diffs = []

    with torch.no_grad():
        for its, batch_data in enumerate(test_loader):
            gt_motion = batch_data.to(device).float()
            n = gt_motion.shape[1]
            remain = n%8

            if remain != 0:
                gt_motion = gt_motion[:, :-remain, :]

            gt_ori = gt_motion.clone()
            gt_motion = gt_motion[...,mask] # (bs, 64, dim)
            pred_motion, loss_commit, perplexity = net(gt_motion).values()
            diff = pred_motion - gt_motion

            # pred_motion = pred_motion
            rec_motion = gt_ori.clone()

            rec_motion[..., mask] = pred_motion # it is already a 6d tensor

            n = rec_motion.shape[1]

            # ç®€åŒ–é‡å»º - åªåº”ç”¨åå½’ä¸€åŒ–åˆ°æ©ç éƒ¨åˆ†
            rec_motion_part = rec_motion[..., :-103] * std_pose + mean_pose #æŠŠmaskæ”¹æˆ:-103
            gt_motion_part = gt_ori[..., :-103] * std_pose + mean_pose

            l2_batch = torch.sqrt(torch.sum(diff ** 2, dim=[1, 2])).mean().item()
            l2_all += l2_batch

            # æ”¶é›†æ½œåœ¨è¡¨ç¤ºç”¨äºFIDè®¡ç®—
            remain = n % 32
            latent_out.append(eval_copy.map2latent(rec_motion_part[:, :n-remain]).reshape(-1, 240).detach().cpu().numpy())
            latent_ori.append(eval_copy.map2latent(gt_motion_part[:, :n-remain]).reshape(-1, 240).detach().cpu().numpy())
            diffs.append(diff[:, :n-remain].reshape(-1, 32).detach().cpu().numpy())

        latent_out_all = np.concatenate(latent_out, axis=0)
        latent_ori_all = np.concatenate(latent_ori, axis=0)
        diffs_all = np.concatenate(diffs, axis=0)

        fid = data_tools.FIDCalculator.frechet_distance(latent_out_all, latent_ori_all)
        logger.info(f"Evaluation FID: {fid:.6f}")

        avg_l2 = l2_all / len(test_loader)
        logger.info(f"Evaluation L2 distance: {avg_l2:.6f}")

logger.info("Script completed successfully!")