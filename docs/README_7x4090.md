# RVQ-VAE 多GPU训练脚本 (7x4090)

基于RVQ-VAE架构文档配置的多GPU训练脚本，适用于7张NVIDIA RTX 4090显卡。

## 文件说明

1. `train_8x4090.sh` - Bash版本的训练脚本 (使用GPU 1-7)
2. `train_8x4090.py` - Python版本的训练脚本（推荐使用，更灵活，使用GPU 1-7）
3. `monitor_gpu.py` - GPU显存监控脚本，会检查GPU 0是否空闲

## 使用方法

### 1. 基本训练命令

使用Bash脚本：
```bash
bash train_8x4090.sh
```

使用Python脚本：
```bash
python train_8x4090.py
```

### 2. 自定义参数

使用Python脚本可以轻松自定义参数：
```bash
# 使用更大的批次大小
python train_8x4090.py --batch_size 160

# 使用更大的网络
python train_8x4090.py --width 1536 --depth 5 --num_quantizers 16

# 使用不同的数据路径
python train_8x4090.py --data_path /path/to/your/data
```

### 3. 监控显存使用

在另一个终端中运行：
```bash
# 每5秒刷新一次，持续监控
python monitor_gpu.py

# 每2秒刷新一次，监控100次
python monitor_gpu.py 2 --count 100
```

## 参数调整原理

为了充分利用8个4090显卡的192GB总显存，我们对以下参数进行了优化：

### 模型参数优化

1. **增大码本大小** (`nb_code`): 从512增加到1024
   - 增加模型表达能力，但会增加显存使用

2. **增加网络宽度** (`width`): 从512增加到1024
   - 每层神经元数量翻倍，提高模型容量

3. **增加网络深度** (`depth`): 从3增加到4
   - 增加网络层数，提高模型复杂度

4. **增加下采样层数** (`down_t`): 从2增加到3
   - 更多的下采样层，提高特征提取能力

5. **增加量化器数量** (`num_quantizers`): 从8增加到12
   - 更多的量化器，提高量化精度

6. **不共享码本** (`shared_codebook`): 设置为False
   - 每个量化器使用独立的码本，增加模型容量

### 训练参数优化

1. **增大批次大小** (`batch_size`): 从256增加到128（每个GPU）
   - 总批次大小从256增加到1024（128 * 8）
   - 更大的批次大小可以提高训练稳定性，但会增加显存使用

2. **增加总迭代次数** (`total_iter`): 从10000增加到20000
   - 更长的训练时间，充分利用更大的模型容量

3. **增大窗口大小** (`window_size`): 从64增加到120
   - 更长的序列输入，提高模型对长期依赖的建模能力

4. **增大窗口步长** (`window_stride`): 从20增加到40
   - 与更大的窗口大小相匹配

## 训练参数

- **批次大小**: 80 (每个GPU，与beat数据集一致)
- **总有效批次大小**: 560 (80 × 7)
- **学习率**: 2e-4 (与架构文档一致)
- **学习率调度**: 在第50000、200000和400000步时降低学习率
- **学习率衰减因子**: 0.05
- **总迭代次数**: 300,000 (与架构文档一致)
- **梯度裁剪**: 1.0
- **重建损失**: L1平滑损失
- **提交损失权重**: 0.02 (与架构文档一致)
- **速度损失权重**: 0.5 (与架构文档一致)

## 模型参数

- **码本大小**: 1024 (与架构文档一致)
- **码本维度**: 128 (与架构文档一致)
- **下采样层数**: 2 (与架构文档一致)
- **网络宽度**: 512 (与架构文档一致)
- **网络深度**: 3 (与架构文档一致)
- **量化器数量**: 6 (与架构文档一致)
- **时间步长**: 2 (与架构文档一致)

## 数据参数

- **窗口大小**: 128 (与架构文档一致)
- **窗口步长**: 64 (与架构文档一致)

## 显存使用估算

基于7个4090显卡的配置，每个GPU的显存使用情况大致如下：

- **模型参数**: ~6GB (与RVQ-VAE架构文档配置一致)
- **优化器状态**: ~6GB
- **梯度**: ~6GB
- **激活值**: ~3GB
- **数据批次**: ~1.5GB
- **其他开销**: ~1.5GB

**总计**: ~24GB/GPU (在4090的48GB显存范围内)

7个GPU的总显存使用量约为168GB，有效利用了多GPU并行训练的优势。

### GPU 0 状态监控

使用以下命令监控GPU状态，确保GPU 0保持空闲：
```bash
python monitor_gpu.py
```

或者使用nvidia-smi实时监控：
```bash
watch -n 1 nvidia-smi
```

## 注意事项

1. **显存不足处理**：如果遇到显存不足错误，可以逐步减小`batch_size`参数，每次减少16。

2. **数据加载优化**：脚本中已设置`num_workers=0`以避免多进程问题，如果需要提高数据加载速度，可以尝试增加`num_workers`。

3. **学习率调整**：增大批次大小后，可能需要相应调整学习率。可以尝试使用线性缩放规则：`new_lr = old_lr * new_batch_size / old_batch_size`。

4. **梯度累积**：如果显存仍然不足，可以考虑实现梯度累积，以使用更大的有效批次大小。

## 故障排除

1. **NCCL错误**：如果遇到NCCL相关错误，可以尝试设置不同的`master_port`或添加以下环境变量：
   ```bash
   export NCCL_DEBUG=INFO
   export NCCL_SOCKET_IFNAME=^docker0,lo
   export NCCL_IB_DISABLE=1
   ```

2. **进程挂起**：如果训练进程挂起，可以尝试减少`batch_size`或减小模型参数。

3. **性能下降**：如果训练速度过慢，可以检查数据加载是否是瓶颈，考虑使用SSD存储数据。

## 进阶优化

1. **混合精度训练**：可以添加`--mixed_precision`参数启用混合精度训练，减少显存使用并提高训练速度。

2. **梯度检查点**：可以添加`--gradient_checkpointing`参数启用梯度检查点，以减少显存使用。

3. **动态批次大小**：可以根据序列长度动态调整批次大小，以最大化显存利用率。

## 示例命令

```bash
# 使用最大可能的模型和批次大小
python train_8x4090.py --width 1536 --depth 5 --num_quantizers 16 --batch_size 160

# 使用混合精度训练（如果支持）
python train_8x4090.py --mixed_precision

# 使用梯度检查点（如果支持）
python train_8x4090.py --gradient_checkpointing

# 使用更长的序列
python train_8x4090.py --window_size 160 --window_stride 60
```